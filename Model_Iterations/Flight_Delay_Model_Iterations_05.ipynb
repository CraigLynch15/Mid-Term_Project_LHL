{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2c9b6d",
   "metadata": {},
   "source": [
    "# Optimizing Model - Optuna Parameter Optimization for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3adfcaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Iteration 5\n",
    "## Feature Eng: Parameter optimization using Optuna model for LightGBM,  \n",
    "##              Parameter optimization using gridsearchcv model for XGBoost,  \n",
    "## Purpose: To measure the effects of parameter optimization\n",
    "## Results : \n",
    "##      LightGBM Model RMSE is:  36.81037880022666 (-4.19% change)\n",
    "##      LightGBM Model R2 Score is:  0.25150748630315467 (34.70% change)\n",
    "##      LightGBM Model Cross-validation MAE is: 21.608509540616378 (-2.54% change)\n",
    "##      XGBoostModel RMSE is:  41.648609711673814\n",
    "##      XGBoost Model R2 Score is:  0.05225789444813955\n",
    "##      XGBoost Model Cross-validation MAE is: 22.453367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8abd41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0515bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flight_info = pd.read_csv('/Users/craiglynch/Desktop/Lighthouse_Labs/Mid-term_Project/mid-term-project-I-master/Regression_no_outliers_cleaned_data_03.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8467b091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(979648, 24)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_flight_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f3da1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_weather = pd.read_csv('/Users/craiglynch/Desktop/Lighthouse_Labs/Mid-term_Project/mid-term-project-I-master/weather.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "39d870cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14099, 39)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8c279094",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight_info = data_flight_info.copy()\n",
    "df_weather = data_weather.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "688b423e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ATL    48923\n",
       "ORD    48428\n",
       "DFW    35688\n",
       "DEN    33907\n",
       "LAX    30969\n",
       "CLT    30851\n",
       "SEA    23313\n",
       "PHX    22252\n",
       "SFO    22183\n",
       "IAH    22017\n",
       "DTW    21795\n",
       "LAS    20661\n",
       "LGA    20597\n",
       "MSP    19965\n",
       "EWR    19453\n",
       "BOS    18365\n",
       "MCO    17474\n",
       "DCA    17438\n",
       "Name: origin, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only want top 19 busiest airports\n",
    "airports = ['ORD','ATL','DFW','DEN','LAX','CLT','SEA','SFO','EWR','LGA','PHX','IAH','LAS','BOS','MCO','DTW','PHIL','DCA','MSP']\n",
    "df_flight_info = df_flight_info[df_flight_info['origin'].isin(airports)]\n",
    "df_flight_info.origin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ffd9ec3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sunny     5503\n",
       "cloudy    4324\n",
       "rain      2860\n",
       "snow      1412\n",
       "Name: weather_type, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather['value'] = df_weather['value'].str.lower()\n",
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    (df_weather['value'].str.contains('sunny')),\n",
    "    (df_weather['value'].str.contains('cloud')),\n",
    "    (df_weather['value'].str.contains('mist')),\n",
    "    (df_weather['value'].str.contains('fog')),\n",
    "    (df_weather['value'].str.contains('overcast')),\n",
    "    (df_weather['value'].str.contains('rain')),\n",
    "    (df_weather['value'].str.contains('drizzle')),\n",
    "    (df_weather['value'].str.contains('thunder')),\n",
    "    (df_weather['value'].str.contains('snow')),\n",
    "    (df_weather['value'].str.contains('sleet')),\n",
    "    (df_weather['value'].str.contains('blizzard')),\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = ['sunny', 'cloudy', 'cloudy','cloudy','cloudy','rain','rain','rain','snow','snow','snow']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df_weather['weather_type'] = np.select(conditions, values)\n",
    "df_weather['weather_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c0bce729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14099"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather['value'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9f53ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating year, month, date columns\n",
    "df_weather['year'] = pd.DatetimeIndex(df_weather['date']).year\n",
    "df_weather['month'] = pd.DatetimeIndex(df_weather['date']).month\n",
    "df_weather['day'] = pd.DatetimeIndex(df_weather['date']).day\n",
    "df_weather['weekday'] = ((pd.DatetimeIndex(df_weather['date']).dayofweek))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc32db9",
   "metadata": {},
   "source": [
    "#### Merging weather data with flight data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "305b8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.rename(columns={'date': 'fl_date', 'airport_code': 'origin'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a3be7273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight_info = pd.merge(df_flight_info, df_weather[['fl_date','origin','weather_type']],  how='left', left_on=['fl_date','origin'], right_on = ['fl_date','origin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dd1261b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518202, 25)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flight_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e48a3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the small number of null weather types\n",
    "df_flight_info = df_flight_info.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "46e5b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding average route times\n",
    "df_flight_info['flight_number'] = df_flight_info['op_unique_carrier'] + df_flight_info['op_carrier_fl_num'].astype(str)\n",
    "route_time_grouped = df_flight_info.groupby(by='flight_number').mean()\n",
    "route_time_grouped.reset_index(inplace=True)\n",
    "route_time_grouped['average_route_time'] = route_time_grouped['actual_elapsed_time']\n",
    "route_time_grouped = route_time_grouped[['flight_number','average_route_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5adce5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Average Carrier Delay - Grouped by Carrier\n",
    "carrier_grouped = df_flight_info.groupby(by='op_unique_carrier').mean()\n",
    "carrier_grouped.reset_index(inplace=True)\n",
    "carrier_grouped['total_carrier_delay'] = carrier_grouped['carrier_delay'] + carrier_grouped['late_aircraft_delay']\n",
    "carrier_grouped = carrier_grouped[['op_unique_carrier', 'total_carrier_delay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f11055f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Average Weather Delay\n",
    "weather_grouped1 = df_flight_info.groupby(by=['origin','month']).mean()\n",
    "weather_grouped1.reset_index(inplace=True)\n",
    "weather_grouped1['total_weather_delay'] = weather_grouped1['weather_delay']\n",
    "weather_grouped1 = weather_grouped1[['origin','total_weather_delay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "68d72a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Average NAS Delay - Grouped by Flight Number\n",
    "nas_grouped = df_flight_info.groupby(by='flight_number').mean()\n",
    "nas_grouped.reset_index(inplace=True)\n",
    "nas_grouped['total_nas_delay'] = nas_grouped['nas_delay']\n",
    "nas_grouped = nas_grouped[['flight_number', 'total_nas_delay']]\n",
    "\n",
    "# Getting Average Security Delay\n",
    "security_grouped = df_flight_info.groupby(by='origin').mean()\n",
    "security_grouped.reset_index(inplace=True)\n",
    "security_grouped['total_security_delay'] = security_grouped['security_delay']\n",
    "security_grouped = security_grouped[['origin','total_security_delay']]\n",
    "\n",
    "# Getting Average Departure Delays by Route\n",
    "dep_delay_grouped = df_flight_info.groupby(by='flight_number').mean()\n",
    "dep_delay_grouped.reset_index(inplace=True)\n",
    "dep_delay_grouped['total_dep_delay'] = dep_delay_grouped['dep_delay']\n",
    "dep_delay_grouped = dep_delay_grouped[['flight_number','total_dep_delay']]\n",
    "\n",
    "# Getting Average Arrival Delays by Route\n",
    "arr_delay_grouped = df_flight_info.groupby(by='flight_number').mean()\n",
    "arr_delay_grouped.reset_index(inplace=True)\n",
    "arr_delay_grouped['total_arr_delay'] = arr_delay_grouped['arr_delay']\n",
    "arr_delay_grouped = arr_delay_grouped[['flight_number','total_arr_delay']]\n",
    "\n",
    "#Merge averages dataframes with original \n",
    "df_flight_info = df_flight_info.merge(security_grouped, on = 'origin', how = 'outer')\n",
    "df_flight_info = df_flight_info.merge(nas_grouped, on = 'flight_number', how = 'outer')\n",
    "df_flight_info = df_flight_info.merge(route_time_grouped, on = 'flight_number', how = 'outer')\n",
    "df_flight_info = df_flight_info.merge(dep_delay_grouped, on = 'flight_number', how = 'outer')\n",
    "df_flight_info = df_flight_info.merge(arr_delay_grouped, on = 'flight_number', how = 'outer')\n",
    "df_flight_info = df_flight_info.merge(weather_grouped1, on = 'origin', how = 'outer')\n",
    "df_flight_info = df_flight_info.merge(carrier_grouped, on = 'op_unique_carrier', how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54957203",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "77e2d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_flight_info.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7e48ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, r2_score, f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "afe270a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding df_flight_info \n",
    "df_flight_info[\"weather_type\"] = df_flight_info[\"weather_type\"].astype('category').cat.codes\n",
    "df_flight_info[\"flight_number\"] = df_flight_info[\"flight_number\"].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "60ffd910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fl_date                  object\n",
       "mkt_unique_carrier       object\n",
       "op_unique_carrier        object\n",
       "op_carrier_fl_num         int64\n",
       "origin                   object\n",
       "crs_dep_time              int64\n",
       "dep_time                float64\n",
       "dep_delay               float64\n",
       "dest                     object\n",
       "arr_time                float64\n",
       "arr_delay               float64\n",
       "crs_arr_time              int64\n",
       "crs_elapsed_time        float64\n",
       "actual_elapsed_time     float64\n",
       "distance                float64\n",
       "carrier_delay           float64\n",
       "weather_delay           float64\n",
       "nas_delay               float64\n",
       "security_delay          float64\n",
       "late_aircraft_delay     float64\n",
       "year                      int64\n",
       "month                     int64\n",
       "day                       int64\n",
       "weekday                 float64\n",
       "weather_type               int8\n",
       "flight_number             int16\n",
       "total_security_delay    float64\n",
       "total_nas_delay         float64\n",
       "average_route_time      float64\n",
       "total_dep_delay         float64\n",
       "total_arr_delay         float64\n",
       "total_weather_delay     float64\n",
       "total_carrier_delay     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flight_info.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de25d4bd",
   "metadata": {},
   "source": [
    "### Adding Total Weather Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b8e73c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight_info = shuffle(df_flight_info)\n",
    "X = df_flight_info[['crs_dep_time','flight_number','crs_elapsed_time','average_route_time','crs_arr_time','distance','year','month','day','weekday','total_carrier_delay', 'total_security_delay','total_nas_delay','total_dep_delay','total_arr_delay','weather_type','total_weather_delay']]\n",
    "y = df_flight_info['arr_delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f7083582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957633ec",
   "metadata": {},
   "source": [
    "##### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dfcf2aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.275636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.9409\n",
      "[4]\tvalid_0's rmse: 41.5245\n",
      "[6]\tvalid_0's rmse: 41.2351\n",
      "[8]\tvalid_0's rmse: 41.0297\n",
      "[10]\tvalid_0's rmse: 40.8781\n",
      "[12]\tvalid_0's rmse: 40.7623\n",
      "[14]\tvalid_0's rmse: 40.6732\n",
      "[16]\tvalid_0's rmse: 40.5993\n",
      "[18]\tvalid_0's rmse: 40.5374\n",
      "[20]\tvalid_0's rmse: 40.4858\n",
      "[22]\tvalid_0's rmse: 40.4414\n",
      "[24]\tvalid_0's rmse: 40.3958\n",
      "[26]\tvalid_0's rmse: 40.3514\n",
      "[28]\tvalid_0's rmse: 40.3202\n",
      "[30]\tvalid_0's rmse: 40.2887\n",
      "[32]\tvalid_0's rmse: 40.2553\n",
      "[34]\tvalid_0's rmse: 40.2196\n",
      "[36]\tvalid_0's rmse: 40.1851\n",
      "[38]\tvalid_0's rmse: 40.1428\n",
      "[40]\tvalid_0's rmse: 40.1145\n",
      "[42]\tvalid_0's rmse: 40.0774\n",
      "[44]\tvalid_0's rmse: 40.0491\n",
      "[46]\tvalid_0's rmse: 40.0246\n",
      "[48]\tvalid_0's rmse: 39.9947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 39.969336:  14%|#4        | 1/7 [00:28<02:48, 28.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 39.9693\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 39.9693\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.9751\n",
      "[4]\tvalid_0's rmse: 41.5962\n",
      "[6]\tvalid_0's rmse: 41.3761\n",
      "[8]\tvalid_0's rmse: 41.1531\n",
      "[10]\tvalid_0's rmse: 41.0436\n",
      "[12]\tvalid_0's rmse: 40.9556\n",
      "[14]\tvalid_0's rmse: 40.8404\n",
      "[16]\tvalid_0's rmse: 40.7544\n",
      "[18]\tvalid_0's rmse: 40.6926\n",
      "[20]\tvalid_0's rmse: 40.6213\n",
      "[22]\tvalid_0's rmse: 40.5738\n",
      "[24]\tvalid_0's rmse: 40.5276\n",
      "[26]\tvalid_0's rmse: 40.4958\n",
      "[28]\tvalid_0's rmse: 40.4692\n",
      "[30]\tvalid_0's rmse: 40.4261\n",
      "[32]\tvalid_0's rmse: 40.4012\n",
      "[34]\tvalid_0's rmse: 40.3513\n",
      "[36]\tvalid_0's rmse: 40.3159\n",
      "[38]\tvalid_0's rmse: 40.2912\n",
      "[40]\tvalid_0's rmse: 40.2719\n",
      "[42]\tvalid_0's rmse: 40.2505\n",
      "[44]\tvalid_0's rmse: 40.2284\n",
      "[46]\tvalid_0's rmse: 40.2143\n",
      "[48]\tvalid_0's rmse: 40.1983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 39.969336:  29%|##8       | 2/7 [00:51<02:07, 25.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 40.1741\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 40.1741\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.9394\n",
      "[4]\tvalid_0's rmse: 41.5181\n",
      "[6]\tvalid_0's rmse: 41.2301\n",
      "[8]\tvalid_0's rmse: 41.0279\n",
      "[10]\tvalid_0's rmse: 40.8769\n",
      "[12]\tvalid_0's rmse: 40.7673\n",
      "[14]\tvalid_0's rmse: 40.6816\n",
      "[16]\tvalid_0's rmse: 40.6145\n",
      "[18]\tvalid_0's rmse: 40.5402\n",
      "[20]\tvalid_0's rmse: 40.4926\n",
      "[22]\tvalid_0's rmse: 40.4441\n",
      "[24]\tvalid_0's rmse: 40.3994\n",
      "[26]\tvalid_0's rmse: 40.3546\n",
      "[28]\tvalid_0's rmse: 40.3168\n",
      "[30]\tvalid_0's rmse: 40.2738\n",
      "[32]\tvalid_0's rmse: 40.232\n",
      "[34]\tvalid_0's rmse: 40.1929\n",
      "[36]\tvalid_0's rmse: 40.1462\n",
      "[38]\tvalid_0's rmse: 40.115\n",
      "[40]\tvalid_0's rmse: 40.089\n",
      "[42]\tvalid_0's rmse: 40.0572\n",
      "[44]\tvalid_0's rmse: 40.0261\n",
      "[46]\tvalid_0's rmse: 39.9982\n",
      "[48]\tvalid_0's rmse: 39.9736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 39.945097:  43%|####2     | 3/7 [01:16<01:41, 25.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 39.9451\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 39.9451\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.154871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.9409\n",
      "[4]\tvalid_0's rmse: 41.5404\n",
      "[6]\tvalid_0's rmse: 41.3107\n",
      "[8]\tvalid_0's rmse: 41.0812\n",
      "[10]\tvalid_0's rmse: 40.9192\n",
      "[12]\tvalid_0's rmse: 40.8131\n",
      "[14]\tvalid_0's rmse: 40.721\n",
      "[16]\tvalid_0's rmse: 40.6391\n",
      "[18]\tvalid_0's rmse: 40.5733\n",
      "[20]\tvalid_0's rmse: 40.51\n",
      "[22]\tvalid_0's rmse: 40.4701\n",
      "[24]\tvalid_0's rmse: 40.4182\n",
      "[26]\tvalid_0's rmse: 40.3841\n",
      "[28]\tvalid_0's rmse: 40.355\n",
      "[30]\tvalid_0's rmse: 40.3265\n",
      "[32]\tvalid_0's rmse: 40.2919\n",
      "[34]\tvalid_0's rmse: 40.2592\n",
      "[36]\tvalid_0's rmse: 40.21\n",
      "[38]\tvalid_0's rmse: 40.1755\n",
      "[40]\tvalid_0's rmse: 40.1427\n",
      "[42]\tvalid_0's rmse: 40.1164\n",
      "[44]\tvalid_0's rmse: 40.077\n",
      "[46]\tvalid_0's rmse: 40.062\n",
      "[48]\tvalid_0's rmse: 40.0343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 39.945097:  57%|#####7    | 4/7 [01:44<01:18, 26.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 39.9975\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 39.9975\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.9438\n",
      "[4]\tvalid_0's rmse: 41.5488\n",
      "[6]\tvalid_0's rmse: 41.317\n",
      "[8]\tvalid_0's rmse: 41.0874\n",
      "[10]\tvalid_0's rmse: 40.9231\n",
      "[12]\tvalid_0's rmse: 40.8104\n",
      "[14]\tvalid_0's rmse: 40.7059\n",
      "[16]\tvalid_0's rmse: 40.6313\n",
      "[18]\tvalid_0's rmse: 40.5595\n",
      "[20]\tvalid_0's rmse: 40.5044\n",
      "[22]\tvalid_0's rmse: 40.4556\n",
      "[24]\tvalid_0's rmse: 40.4116\n",
      "[26]\tvalid_0's rmse: 40.3754\n",
      "[28]\tvalid_0's rmse: 40.3381\n",
      "[30]\tvalid_0's rmse: 40.3023\n",
      "[32]\tvalid_0's rmse: 40.2737\n",
      "[34]\tvalid_0's rmse: 40.2446\n",
      "[36]\tvalid_0's rmse: 40.2039\n",
      "[38]\tvalid_0's rmse: 40.1678\n",
      "[40]\tvalid_0's rmse: 40.1409\n",
      "[42]\tvalid_0's rmse: 40.1206\n",
      "[44]\tvalid_0's rmse: 40.0925\n",
      "[46]\tvalid_0's rmse: 40.078\n",
      "[48]\tvalid_0's rmse: 40.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 39.945097:  71%|#######1  | 5/7 [02:16<00:56, 28.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 40.0218\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 40.0218\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.9611\n",
      "[4]\tvalid_0's rmse: 41.5675\n",
      "[6]\tvalid_0's rmse: 41.3458\n",
      "[8]\tvalid_0's rmse: 41.112\n",
      "[10]\tvalid_0's rmse: 40.9524\n",
      "[12]\tvalid_0's rmse: 40.8573\n",
      "[14]\tvalid_0's rmse: 40.7565\n",
      "[16]\tvalid_0's rmse: 40.6688\n",
      "[18]\tvalid_0's rmse: 40.5963\n",
      "[20]\tvalid_0's rmse: 40.5395\n",
      "[22]\tvalid_0's rmse: 40.4944\n",
      "[24]\tvalid_0's rmse: 40.4481\n",
      "[26]\tvalid_0's rmse: 40.4162\n",
      "[28]\tvalid_0's rmse: 40.3893\n",
      "[30]\tvalid_0's rmse: 40.3482\n",
      "[32]\tvalid_0's rmse: 40.3175\n",
      "[34]\tvalid_0's rmse: 40.2728\n",
      "[36]\tvalid_0's rmse: 40.2375\n",
      "[38]\tvalid_0's rmse: 40.2004\n",
      "[40]\tvalid_0's rmse: 40.166\n",
      "[42]\tvalid_0's rmse: 40.1423\n",
      "[44]\tvalid_0's rmse: 40.1182\n",
      "[46]\tvalid_0's rmse: 40.101\n",
      "[48]\tvalid_0's rmse: 40.0741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 39.945097:  86%|########5 | 6/7 [02:54<00:31, 31.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 40.0489\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 40.0489\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.962\n",
      "[4]\tvalid_0's rmse: 41.5693\n",
      "[6]\tvalid_0's rmse: 41.3454\n",
      "[8]\tvalid_0's rmse: 41.1252\n",
      "[10]\tvalid_0's rmse: 41.0044\n",
      "[12]\tvalid_0's rmse: 40.9174\n",
      "[14]\tvalid_0's rmse: 40.8061\n",
      "[16]\tvalid_0's rmse: 40.7166\n",
      "[18]\tvalid_0's rmse: 40.6431\n",
      "[20]\tvalid_0's rmse: 40.5787\n",
      "[22]\tvalid_0's rmse: 40.533\n",
      "[24]\tvalid_0's rmse: 40.489\n",
      "[26]\tvalid_0's rmse: 40.4486\n",
      "[28]\tvalid_0's rmse: 40.4199\n",
      "[30]\tvalid_0's rmse: 40.3805\n",
      "[32]\tvalid_0's rmse: 40.3502\n",
      "[34]\tvalid_0's rmse: 40.3031\n",
      "[36]\tvalid_0's rmse: 40.2619\n",
      "[38]\tvalid_0's rmse: 40.2314\n",
      "[40]\tvalid_0's rmse: 40.2009\n",
      "[42]\tvalid_0's rmse: 40.1703\n",
      "[44]\tvalid_0's rmse: 40.1477\n",
      "[46]\tvalid_0's rmse: 40.133\n",
      "[48]\tvalid_0's rmse: 40.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 39.945097: 100%|##########| 7/7 [03:23<00:00, 29.09s/it]\n",
      "num_leaves, val_score: 39.945097:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 40.0875\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 40.0875\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.138271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7244\n",
      "[4]\tvalid_0's rmse: 41.1353\n",
      "[6]\tvalid_0's rmse: 40.711\n",
      "[8]\tvalid_0's rmse: 40.3893\n",
      "[10]\tvalid_0's rmse: 40.1371\n",
      "[12]\tvalid_0's rmse: 39.9328\n",
      "[14]\tvalid_0's rmse: 39.7624\n",
      "[16]\tvalid_0's rmse: 39.6164\n",
      "[18]\tvalid_0's rmse: 39.4837\n",
      "[20]\tvalid_0's rmse: 39.352\n",
      "[22]\tvalid_0's rmse: 39.2093\n",
      "[24]\tvalid_0's rmse: 39.0907\n",
      "[26]\tvalid_0's rmse: 38.9654\n",
      "[28]\tvalid_0's rmse: 38.8488\n",
      "[30]\tvalid_0's rmse: 38.7239\n",
      "[32]\tvalid_0's rmse: 38.6076\n",
      "[34]\tvalid_0's rmse: 38.4744\n",
      "[36]\tvalid_0's rmse: 38.3524\n",
      "[38]\tvalid_0's rmse: 38.2414\n",
      "[40]\tvalid_0's rmse: 38.1361\n",
      "[42]\tvalid_0's rmse: 38.0641\n",
      "[44]\tvalid_0's rmse: 37.9722\n",
      "[46]\tvalid_0's rmse: 37.8875\n",
      "[48]\tvalid_0's rmse: 37.8042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.722654:   5%|5         | 1/20 [00:35<11:09, 35.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.7227\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.7227\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7186\n",
      "[4]\tvalid_0's rmse: 41.1108\n",
      "[6]\tvalid_0's rmse: 40.6677\n",
      "[8]\tvalid_0's rmse: 40.3331\n",
      "[10]\tvalid_0's rmse: 40.0544\n",
      "[12]\tvalid_0's rmse: 39.847\n",
      "[14]\tvalid_0's rmse: 39.6611\n",
      "[16]\tvalid_0's rmse: 39.5123\n",
      "[18]\tvalid_0's rmse: 39.37\n",
      "[20]\tvalid_0's rmse: 39.2334\n",
      "[22]\tvalid_0's rmse: 39.0984\n",
      "[24]\tvalid_0's rmse: 38.9616\n",
      "[26]\tvalid_0's rmse: 38.826\n",
      "[28]\tvalid_0's rmse: 38.6807\n",
      "[30]\tvalid_0's rmse: 38.5691\n",
      "[32]\tvalid_0's rmse: 38.4152\n",
      "[34]\tvalid_0's rmse: 38.2881\n",
      "[36]\tvalid_0's rmse: 38.1959\n",
      "[38]\tvalid_0's rmse: 38.0649\n",
      "[40]\tvalid_0's rmse: 37.9532\n",
      "[42]\tvalid_0's rmse: 37.8517\n",
      "[44]\tvalid_0's rmse: 37.7587\n",
      "[46]\tvalid_0's rmse: 37.6798\n",
      "[48]\tvalid_0's rmse: 37.5784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.496445:  10%|#         | 2/20 [01:07<10:06, 33.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.4964\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.4964\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.138262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.8534\n",
      "[4]\tvalid_0's rmse: 41.3786\n",
      "[6]\tvalid_0's rmse: 41.0356\n",
      "[8]\tvalid_0's rmse: 40.7838\n",
      "[10]\tvalid_0's rmse: 40.5946\n",
      "[12]\tvalid_0's rmse: 40.4519\n",
      "[14]\tvalid_0's rmse: 40.3369\n",
      "[16]\tvalid_0's rmse: 40.2311\n",
      "[18]\tvalid_0's rmse: 40.1379\n",
      "[20]\tvalid_0's rmse: 40.0655\n",
      "[22]\tvalid_0's rmse: 39.9901\n",
      "[24]\tvalid_0's rmse: 39.9251\n",
      "[26]\tvalid_0's rmse: 39.8643\n",
      "[28]\tvalid_0's rmse: 39.7957\n",
      "[30]\tvalid_0's rmse: 39.7152\n",
      "[32]\tvalid_0's rmse: 39.6522\n",
      "[34]\tvalid_0's rmse: 39.5939\n",
      "[36]\tvalid_0's rmse: 39.5221\n",
      "[38]\tvalid_0's rmse: 39.4569\n",
      "[40]\tvalid_0's rmse: 39.3967\n",
      "[42]\tvalid_0's rmse: 39.3505\n",
      "[44]\tvalid_0's rmse: 39.2921\n",
      "[46]\tvalid_0's rmse: 39.247\n",
      "[48]\tvalid_0's rmse: 39.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.496445:  15%|#5        | 3/20 [01:37<09:03, 31.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 39.1369\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 39.1369\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.159830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7336\n",
      "[4]\tvalid_0's rmse: 41.1415\n",
      "[6]\tvalid_0's rmse: 40.718\n",
      "[8]\tvalid_0's rmse: 40.3941\n",
      "[10]\tvalid_0's rmse: 40.1367\n",
      "[12]\tvalid_0's rmse: 39.9305\n",
      "[14]\tvalid_0's rmse: 39.7539\n",
      "[16]\tvalid_0's rmse: 39.5969\n",
      "[18]\tvalid_0's rmse: 39.4591\n",
      "[20]\tvalid_0's rmse: 39.3449\n",
      "[22]\tvalid_0's rmse: 39.2219\n",
      "[24]\tvalid_0's rmse: 39.1007\n",
      "[26]\tvalid_0's rmse: 38.9829\n",
      "[28]\tvalid_0's rmse: 38.865\n",
      "[30]\tvalid_0's rmse: 38.7358\n",
      "[32]\tvalid_0's rmse: 38.6194\n",
      "[34]\tvalid_0's rmse: 38.4916\n",
      "[36]\tvalid_0's rmse: 38.3925\n",
      "[38]\tvalid_0's rmse: 38.2918\n",
      "[40]\tvalid_0's rmse: 38.1802\n",
      "[42]\tvalid_0's rmse: 38.0538\n",
      "[44]\tvalid_0's rmse: 37.9647\n",
      "[46]\tvalid_0's rmse: 37.871\n",
      "[48]\tvalid_0's rmse: 37.7914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.496445:  20%|##        | 4/20 [02:12<08:46, 32.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.695\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.695\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.142628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.8834\n",
      "[4]\tvalid_0's rmse: 41.4197\n",
      "[6]\tvalid_0's rmse: 41.0944\n",
      "[8]\tvalid_0's rmse: 40.861\n",
      "[10]\tvalid_0's rmse: 40.6814\n",
      "[12]\tvalid_0's rmse: 40.5504\n",
      "[14]\tvalid_0's rmse: 40.4347\n",
      "[16]\tvalid_0's rmse: 40.3512\n",
      "[18]\tvalid_0's rmse: 40.2714\n",
      "[20]\tvalid_0's rmse: 40.2101\n",
      "[22]\tvalid_0's rmse: 40.1433\n",
      "[24]\tvalid_0's rmse: 40.086\n",
      "[26]\tvalid_0's rmse: 40.032\n",
      "[28]\tvalid_0's rmse: 39.9809\n",
      "[30]\tvalid_0's rmse: 39.9313\n",
      "[32]\tvalid_0's rmse: 39.872\n",
      "[34]\tvalid_0's rmse: 39.8114\n",
      "[36]\tvalid_0's rmse: 39.753\n",
      "[38]\tvalid_0's rmse: 39.7093\n",
      "[40]\tvalid_0's rmse: 39.6621\n",
      "[42]\tvalid_0's rmse: 39.6174\n",
      "[44]\tvalid_0's rmse: 39.5711\n",
      "[46]\tvalid_0's rmse: 39.53\n",
      "[48]\tvalid_0's rmse: 39.4884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.496445:  25%|##5       | 5/20 [02:43<08:04, 32.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 39.4433\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 39.4433\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.164893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7925\n",
      "[4]\tvalid_0's rmse: 41.266\n",
      "[6]\tvalid_0's rmse: 40.8828\n",
      "[8]\tvalid_0's rmse: 40.5915\n",
      "[10]\tvalid_0's rmse: 40.3818\n",
      "[12]\tvalid_0's rmse: 40.2028\n",
      "[14]\tvalid_0's rmse: 40.0663\n",
      "[16]\tvalid_0's rmse: 39.9348\n",
      "[18]\tvalid_0's rmse: 39.8189\n",
      "[20]\tvalid_0's rmse: 39.7094\n",
      "[22]\tvalid_0's rmse: 39.6168\n",
      "[24]\tvalid_0's rmse: 39.5239\n",
      "[26]\tvalid_0's rmse: 39.4262\n",
      "[28]\tvalid_0's rmse: 39.3306\n",
      "[30]\tvalid_0's rmse: 39.2399\n",
      "[32]\tvalid_0's rmse: 39.1503\n",
      "[34]\tvalid_0's rmse: 39.0647\n",
      "[36]\tvalid_0's rmse: 38.9674\n",
      "[38]\tvalid_0's rmse: 38.896\n",
      "[40]\tvalid_0's rmse: 38.8004\n",
      "[42]\tvalid_0's rmse: 38.7358\n",
      "[44]\tvalid_0's rmse: 38.66\n",
      "[46]\tvalid_0's rmse: 38.5993\n",
      "[48]\tvalid_0's rmse: 38.5273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.496445:  30%|###       | 6/20 [03:16<07:35, 32.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 38.4568\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 38.4568\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.8193\n",
      "[4]\tvalid_0's rmse: 41.3121\n",
      "[6]\tvalid_0's rmse: 40.949\n",
      "[8]\tvalid_0's rmse: 40.6709\n",
      "[10]\tvalid_0's rmse: 40.4723\n",
      "[12]\tvalid_0's rmse: 40.3084\n",
      "[14]\tvalid_0's rmse: 40.1692\n",
      "[16]\tvalid_0's rmse: 40.0501\n",
      "[18]\tvalid_0's rmse: 39.9557\n",
      "[20]\tvalid_0's rmse: 39.8687\n",
      "[22]\tvalid_0's rmse: 39.7845\n",
      "[24]\tvalid_0's rmse: 39.7014\n",
      "[26]\tvalid_0's rmse: 39.6277\n",
      "[28]\tvalid_0's rmse: 39.5555\n",
      "[30]\tvalid_0's rmse: 39.4703\n",
      "[32]\tvalid_0's rmse: 39.3859\n",
      "[34]\tvalid_0's rmse: 39.306\n",
      "[36]\tvalid_0's rmse: 39.2316\n",
      "[38]\tvalid_0's rmse: 39.1632\n",
      "[40]\tvalid_0's rmse: 39.0867\n",
      "[42]\tvalid_0's rmse: 39.0183\n",
      "[44]\tvalid_0's rmse: 38.9587\n",
      "[46]\tvalid_0's rmse: 38.9139\n",
      "[48]\tvalid_0's rmse: 38.8404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.496445:  35%|###5      | 7/20 [03:48<07:00, 32.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 38.7893\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 38.7893\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.184582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6836\n",
      "[4]\tvalid_0's rmse: 41.0741\n",
      "[6]\tvalid_0's rmse: 40.6133\n",
      "[8]\tvalid_0's rmse: 40.2508\n",
      "[10]\tvalid_0's rmse: 39.9751\n",
      "[12]\tvalid_0's rmse: 39.7482\n",
      "[14]\tvalid_0's rmse: 39.5574\n",
      "[16]\tvalid_0's rmse: 39.3893\n",
      "[18]\tvalid_0's rmse: 39.2378\n",
      "[20]\tvalid_0's rmse: 39.0822\n",
      "[22]\tvalid_0's rmse: 38.9289\n",
      "[24]\tvalid_0's rmse: 38.781\n",
      "[26]\tvalid_0's rmse: 38.6539\n",
      "[28]\tvalid_0's rmse: 38.5151\n",
      "[30]\tvalid_0's rmse: 38.4143\n",
      "[32]\tvalid_0's rmse: 38.2983\n",
      "[34]\tvalid_0's rmse: 38.1653\n",
      "[36]\tvalid_0's rmse: 38.0375\n",
      "[38]\tvalid_0's rmse: 37.9123\n",
      "[40]\tvalid_0's rmse: 37.785\n",
      "[42]\tvalid_0's rmse: 37.6433\n",
      "[44]\tvalid_0's rmse: 37.5285\n",
      "[46]\tvalid_0's rmse: 37.4314\n",
      "[48]\tvalid_0's rmse: 37.3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.250183:  40%|####      | 8/20 [04:21<06:30, 32.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.2502\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.2502\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.139379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7397\n",
      "[4]\tvalid_0's rmse: 41.1554\n",
      "[6]\tvalid_0's rmse: 40.7404\n",
      "[8]\tvalid_0's rmse: 40.4248\n",
      "[10]\tvalid_0's rmse: 40.1701\n",
      "[12]\tvalid_0's rmse: 39.9739\n",
      "[14]\tvalid_0's rmse: 39.8137\n",
      "[16]\tvalid_0's rmse: 39.6772\n",
      "[18]\tvalid_0's rmse: 39.5438\n",
      "[20]\tvalid_0's rmse: 39.417\n",
      "[22]\tvalid_0's rmse: 39.2908\n",
      "[24]\tvalid_0's rmse: 39.1818\n",
      "[26]\tvalid_0's rmse: 39.0632\n",
      "[28]\tvalid_0's rmse: 38.9384\n",
      "[30]\tvalid_0's rmse: 38.8447\n",
      "[32]\tvalid_0's rmse: 38.7282\n",
      "[34]\tvalid_0's rmse: 38.6338\n",
      "[36]\tvalid_0's rmse: 38.5201\n",
      "[38]\tvalid_0's rmse: 38.4293\n",
      "[40]\tvalid_0's rmse: 38.3154\n",
      "[42]\tvalid_0's rmse: 38.2035\n",
      "[44]\tvalid_0's rmse: 38.1374\n",
      "[46]\tvalid_0's rmse: 38.0495\n",
      "[48]\tvalid_0's rmse: 37.9753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.250183:  45%|####5     | 9/20 [04:54<05:59, 32.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.9066\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.9066\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.159525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7348\n",
      "[4]\tvalid_0's rmse: 41.1515\n",
      "[6]\tvalid_0's rmse: 40.7337\n",
      "[8]\tvalid_0's rmse: 40.4186\n",
      "[10]\tvalid_0's rmse: 40.1633\n",
      "[12]\tvalid_0's rmse: 39.9542\n",
      "[14]\tvalid_0's rmse: 39.7929\n",
      "[16]\tvalid_0's rmse: 39.6369\n",
      "[18]\tvalid_0's rmse: 39.4937\n",
      "[20]\tvalid_0's rmse: 39.3618\n",
      "[22]\tvalid_0's rmse: 39.2396\n",
      "[24]\tvalid_0's rmse: 39.1176\n",
      "[26]\tvalid_0's rmse: 39.0065\n",
      "[28]\tvalid_0's rmse: 38.8916\n",
      "[30]\tvalid_0's rmse: 38.7937\n",
      "[32]\tvalid_0's rmse: 38.6832\n",
      "[34]\tvalid_0's rmse: 38.5661\n",
      "[36]\tvalid_0's rmse: 38.4688\n",
      "[38]\tvalid_0's rmse: 38.3748\n",
      "[40]\tvalid_0's rmse: 38.2805\n",
      "[42]\tvalid_0's rmse: 38.178\n",
      "[44]\tvalid_0's rmse: 38.1078\n",
      "[46]\tvalid_0's rmse: 38.0029\n",
      "[48]\tvalid_0's rmse: 37.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.250183:  50%|#####     | 10/20 [05:28<05:32, 33.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.8484\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.8484\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.196828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6762\n",
      "[4]\tvalid_0's rmse: 41.0624\n",
      "[6]\tvalid_0's rmse: 40.6\n",
      "[8]\tvalid_0's rmse: 40.2494\n",
      "[10]\tvalid_0's rmse: 39.9628\n",
      "[12]\tvalid_0's rmse: 39.7285\n",
      "[14]\tvalid_0's rmse: 39.5342\n",
      "[16]\tvalid_0's rmse: 39.3605\n",
      "[18]\tvalid_0's rmse: 39.1855\n",
      "[20]\tvalid_0's rmse: 39.0215\n",
      "[22]\tvalid_0's rmse: 38.8731\n",
      "[24]\tvalid_0's rmse: 38.7245\n",
      "[26]\tvalid_0's rmse: 38.5901\n",
      "[28]\tvalid_0's rmse: 38.4513\n",
      "[30]\tvalid_0's rmse: 38.3135\n",
      "[32]\tvalid_0's rmse: 38.1884\n",
      "[34]\tvalid_0's rmse: 38.056\n",
      "[36]\tvalid_0's rmse: 37.9331\n",
      "[38]\tvalid_0's rmse: 37.8028\n",
      "[40]\tvalid_0's rmse: 37.6839\n",
      "[42]\tvalid_0's rmse: 37.5704\n",
      "[44]\tvalid_0's rmse: 37.4274\n",
      "[46]\tvalid_0's rmse: 37.3308\n",
      "[48]\tvalid_0's rmse: 37.2232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.141423:  55%|#####5    | 11/20 [06:06<05:12, 34.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1414\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1414\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.172287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6757\n",
      "[4]\tvalid_0's rmse: 41.0612\n",
      "[6]\tvalid_0's rmse: 40.598\n",
      "[8]\tvalid_0's rmse: 40.2308\n",
      "[10]\tvalid_0's rmse: 39.9473\n",
      "[12]\tvalid_0's rmse: 39.7141\n",
      "[14]\tvalid_0's rmse: 39.5184\n",
      "[16]\tvalid_0's rmse: 39.3293\n",
      "[18]\tvalid_0's rmse: 39.1621\n",
      "[20]\tvalid_0's rmse: 39.0106\n",
      "[22]\tvalid_0's rmse: 38.8673\n",
      "[24]\tvalid_0's rmse: 38.7198\n",
      "[26]\tvalid_0's rmse: 38.5934\n",
      "[28]\tvalid_0's rmse: 38.4665\n",
      "[30]\tvalid_0's rmse: 38.3017\n",
      "[32]\tvalid_0's rmse: 38.1911\n",
      "[34]\tvalid_0's rmse: 38.0584\n",
      "[36]\tvalid_0's rmse: 37.918\n",
      "[38]\tvalid_0's rmse: 37.7865\n",
      "[40]\tvalid_0's rmse: 37.6752\n",
      "[42]\tvalid_0's rmse: 37.5542\n",
      "[44]\tvalid_0's rmse: 37.4404\n",
      "[46]\tvalid_0's rmse: 37.3497\n",
      "[48]\tvalid_0's rmse: 37.2532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.141423:  60%|######    | 12/20 [06:44<04:44, 35.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1449\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1449\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6757\n",
      "[4]\tvalid_0's rmse: 41.0612\n",
      "[6]\tvalid_0's rmse: 40.598\n",
      "[8]\tvalid_0's rmse: 40.2308\n",
      "[10]\tvalid_0's rmse: 39.9473\n",
      "[12]\tvalid_0's rmse: 39.7141\n",
      "[14]\tvalid_0's rmse: 39.5184\n",
      "[16]\tvalid_0's rmse: 39.3293\n",
      "[18]\tvalid_0's rmse: 39.1621\n",
      "[20]\tvalid_0's rmse: 39.0106\n",
      "[22]\tvalid_0's rmse: 38.8673\n",
      "[24]\tvalid_0's rmse: 38.7198\n",
      "[26]\tvalid_0's rmse: 38.5934\n",
      "[28]\tvalid_0's rmse: 38.4665\n",
      "[30]\tvalid_0's rmse: 38.3017\n",
      "[32]\tvalid_0's rmse: 38.1911\n",
      "[34]\tvalid_0's rmse: 38.0584\n",
      "[36]\tvalid_0's rmse: 37.918\n",
      "[38]\tvalid_0's rmse: 37.7865\n",
      "[40]\tvalid_0's rmse: 37.6752\n",
      "[42]\tvalid_0's rmse: 37.5542\n",
      "[44]\tvalid_0's rmse: 37.4404\n",
      "[46]\tvalid_0's rmse: 37.3497\n",
      "[48]\tvalid_0's rmse: 37.2532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.141423:  65%|######5   | 13/20 [07:20<04:10, 35.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1449\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "num_leaves, val_score: 37.141423:  65%|######5   | 13/20 [07:20<04:10, 35.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.148224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 42.0072\n",
      "[4]\tvalid_0's rmse: 41.6348\n",
      "[6]\tvalid_0's rmse: 41.3759\n",
      "[8]\tvalid_0's rmse: 41.189\n",
      "[10]\tvalid_0's rmse: 41.0584\n",
      "[12]\tvalid_0's rmse: 40.9644\n",
      "[14]\tvalid_0's rmse: 40.8954\n",
      "[16]\tvalid_0's rmse: 40.8442\n",
      "[18]\tvalid_0's rmse: 40.8014\n",
      "[20]\tvalid_0's rmse: 40.7666\n",
      "[22]\tvalid_0's rmse: 40.7331\n",
      "[24]\tvalid_0's rmse: 40.7002\n",
      "[26]\tvalid_0's rmse: 40.6734\n",
      "[28]\tvalid_0's rmse: 40.6405\n",
      "[30]\tvalid_0's rmse: 40.6222\n",
      "[32]\tvalid_0's rmse: 40.5993\n",
      "[34]\tvalid_0's rmse: 40.5779\n",
      "[36]\tvalid_0's rmse: 40.565\n",
      "[38]\tvalid_0's rmse: 40.5458\n",
      "[40]\tvalid_0's rmse: 40.5334\n",
      "[42]\tvalid_0's rmse: 40.5177\n",
      "[44]\tvalid_0's rmse: 40.5032\n",
      "[46]\tvalid_0's rmse: 40.4898\n",
      "[48]\tvalid_0's rmse: 40.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.141423:  70%|#######   | 14/20 [07:45<03:14, 32.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 40.4615\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 40.4615\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6882\n",
      "[4]\tvalid_0's rmse: 41.0817\n",
      "[6]\tvalid_0's rmse: 40.6187\n",
      "[8]\tvalid_0's rmse: 40.2661\n",
      "[10]\tvalid_0's rmse: 39.9877\n",
      "[12]\tvalid_0's rmse: 39.7536\n",
      "[14]\tvalid_0's rmse: 39.5647\n",
      "[16]\tvalid_0's rmse: 39.3893\n",
      "[18]\tvalid_0's rmse: 39.226\n",
      "[20]\tvalid_0's rmse: 39.0719\n",
      "[22]\tvalid_0's rmse: 38.9137\n",
      "[24]\tvalid_0's rmse: 38.7565\n",
      "[26]\tvalid_0's rmse: 38.6301\n",
      "[28]\tvalid_0's rmse: 38.5087\n",
      "[30]\tvalid_0's rmse: 38.3789\n",
      "[32]\tvalid_0's rmse: 38.2423\n",
      "[34]\tvalid_0's rmse: 38.1112\n",
      "[36]\tvalid_0's rmse: 37.9862\n",
      "[38]\tvalid_0's rmse: 37.837\n",
      "[40]\tvalid_0's rmse: 37.7418\n",
      "[42]\tvalid_0's rmse: 37.6422\n",
      "[44]\tvalid_0's rmse: 37.5069\n",
      "[46]\tvalid_0's rmse: 37.4338\n",
      "[48]\tvalid_0's rmse: 37.3168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.141423:  75%|#######5  | 15/20 [08:23<02:50, 34.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.2409\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.2409\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.270897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7082\n",
      "[4]\tvalid_0's rmse: 41.0905\n",
      "[6]\tvalid_0's rmse: 40.6452\n",
      "[8]\tvalid_0's rmse: 40.3031\n",
      "[10]\tvalid_0's rmse: 40.0256\n",
      "[12]\tvalid_0's rmse: 39.8084\n",
      "[14]\tvalid_0's rmse: 39.6299\n",
      "[16]\tvalid_0's rmse: 39.4611\n",
      "[18]\tvalid_0's rmse: 39.2947\n",
      "[20]\tvalid_0's rmse: 39.1528\n",
      "[22]\tvalid_0's rmse: 39.0005\n",
      "[24]\tvalid_0's rmse: 38.8605\n",
      "[26]\tvalid_0's rmse: 38.736\n",
      "[28]\tvalid_0's rmse: 38.6261\n",
      "[30]\tvalid_0's rmse: 38.5085\n",
      "[32]\tvalid_0's rmse: 38.3881\n",
      "[34]\tvalid_0's rmse: 38.2663\n",
      "[36]\tvalid_0's rmse: 38.1243\n",
      "[38]\tvalid_0's rmse: 38.0454\n",
      "[40]\tvalid_0's rmse: 37.92\n",
      "[42]\tvalid_0's rmse: 37.8173\n",
      "[44]\tvalid_0's rmse: 37.7198\n",
      "[46]\tvalid_0's rmse: 37.6008\n",
      "[48]\tvalid_0's rmse: 37.5141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.141423:  80%|########  | 16/20 [08:59<02:18, 34.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.4297\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.4297\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.157450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7576\n",
      "[4]\tvalid_0's rmse: 41.1942\n",
      "[6]\tvalid_0's rmse: 40.7946\n",
      "[8]\tvalid_0's rmse: 40.4974\n",
      "[10]\tvalid_0's rmse: 40.2757\n",
      "[12]\tvalid_0's rmse: 40.0775\n",
      "[14]\tvalid_0's rmse: 39.9174\n",
      "[16]\tvalid_0's rmse: 39.7822\n",
      "[18]\tvalid_0's rmse: 39.655\n",
      "[20]\tvalid_0's rmse: 39.5275\n",
      "[22]\tvalid_0's rmse: 39.4235\n",
      "[24]\tvalid_0's rmse: 39.3184\n",
      "[26]\tvalid_0's rmse: 39.2231\n",
      "[28]\tvalid_0's rmse: 39.1259\n",
      "[30]\tvalid_0's rmse: 39.0292\n",
      "[32]\tvalid_0's rmse: 38.9381\n",
      "[34]\tvalid_0's rmse: 38.8373\n",
      "[36]\tvalid_0's rmse: 38.7299\n",
      "[38]\tvalid_0's rmse: 38.6506\n",
      "[40]\tvalid_0's rmse: 38.5539\n",
      "[42]\tvalid_0's rmse: 38.4621\n",
      "[44]\tvalid_0's rmse: 38.3934\n",
      "[46]\tvalid_0's rmse: 38.3278\n",
      "[48]\tvalid_0's rmse: 38.2386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.141423:  85%|########5 | 17/20 [09:30<01:41, 33.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 38.1714\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 38.1714\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.173133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6785\n",
      "[4]\tvalid_0's rmse: 41.0682\n",
      "[6]\tvalid_0's rmse: 40.6108\n",
      "[8]\tvalid_0's rmse: 40.2466\n",
      "[10]\tvalid_0's rmse: 39.9638\n",
      "[12]\tvalid_0's rmse: 39.738\n",
      "[14]\tvalid_0's rmse: 39.5415\n",
      "[16]\tvalid_0's rmse: 39.3598\n",
      "[18]\tvalid_0's rmse: 39.1857\n",
      "[20]\tvalid_0's rmse: 39.0511\n",
      "[22]\tvalid_0's rmse: 38.9012\n",
      "[24]\tvalid_0's rmse: 38.7159\n",
      "[26]\tvalid_0's rmse: 38.5684\n",
      "[28]\tvalid_0's rmse: 38.4515\n",
      "[30]\tvalid_0's rmse: 38.3313\n",
      "[32]\tvalid_0's rmse: 38.1837\n",
      "[34]\tvalid_0's rmse: 38.0575\n",
      "[36]\tvalid_0's rmse: 37.9209\n",
      "[38]\tvalid_0's rmse: 37.802\n",
      "[40]\tvalid_0's rmse: 37.6903\n",
      "[42]\tvalid_0's rmse: 37.5769\n",
      "[44]\tvalid_0's rmse: 37.4648\n",
      "[46]\tvalid_0's rmse: 37.3906\n",
      "[48]\tvalid_0's rmse: 37.2878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.141423:  90%|######### | 18/20 [10:10<01:11, 35.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1808\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1808\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.153939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7046\n",
      "[4]\tvalid_0's rmse: 41.0856\n",
      "[6]\tvalid_0's rmse: 40.6386\n",
      "[8]\tvalid_0's rmse: 40.3055\n",
      "[10]\tvalid_0's rmse: 40.0358\n",
      "[12]\tvalid_0's rmse: 39.8081\n",
      "[14]\tvalid_0's rmse: 39.6305\n",
      "[16]\tvalid_0's rmse: 39.4732\n",
      "[18]\tvalid_0's rmse: 39.3106\n",
      "[20]\tvalid_0's rmse: 39.1621\n",
      "[22]\tvalid_0's rmse: 39.0277\n",
      "[24]\tvalid_0's rmse: 38.8972\n",
      "[26]\tvalid_0's rmse: 38.7625\n",
      "[28]\tvalid_0's rmse: 38.6419\n",
      "[30]\tvalid_0's rmse: 38.5174\n",
      "[32]\tvalid_0's rmse: 38.3742\n",
      "[34]\tvalid_0's rmse: 38.2463\n",
      "[36]\tvalid_0's rmse: 38.0781\n",
      "[38]\tvalid_0's rmse: 37.9815\n",
      "[40]\tvalid_0's rmse: 37.8716\n",
      "[42]\tvalid_0's rmse: 37.7855\n",
      "[44]\tvalid_0's rmse: 37.6773\n",
      "[46]\tvalid_0's rmse: 37.6038\n",
      "[48]\tvalid_0's rmse: 37.4985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.141423:  95%|#########5| 19/20 [10:45<00:35, 35.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.3935\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.3935\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.170384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 42.1438\n",
      "[4]\tvalid_0's rmse: 41.8456\n",
      "[6]\tvalid_0's rmse: 41.6272\n",
      "[8]\tvalid_0's rmse: 41.4687\n",
      "[10]\tvalid_0's rmse: 41.346\n",
      "[12]\tvalid_0's rmse: 41.2562\n",
      "[14]\tvalid_0's rmse: 41.186\n",
      "[16]\tvalid_0's rmse: 41.1306\n",
      "[18]\tvalid_0's rmse: 41.085\n",
      "[20]\tvalid_0's rmse: 41.0461\n",
      "[22]\tvalid_0's rmse: 41.0143\n",
      "[24]\tvalid_0's rmse: 40.9885\n",
      "[26]\tvalid_0's rmse: 40.9653\n",
      "[28]\tvalid_0's rmse: 40.9458\n",
      "[30]\tvalid_0's rmse: 40.9246\n",
      "[32]\tvalid_0's rmse: 40.9091\n",
      "[34]\tvalid_0's rmse: 40.8919\n",
      "[36]\tvalid_0's rmse: 40.8806\n",
      "[38]\tvalid_0's rmse: 40.8665\n",
      "[40]\tvalid_0's rmse: 40.8562\n",
      "[42]\tvalid_0's rmse: 40.8478\n",
      "[44]\tvalid_0's rmse: 40.8407\n",
      "[46]\tvalid_0's rmse: 40.8328\n",
      "[48]\tvalid_0's rmse: 40.8256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 37.141423: 100%|##########| 20/20 [11:03<00:00, 33.17s/it]\n",
      "bagging, val_score: 37.141423:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 40.8178\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 40.8178\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.139603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6949\n",
      "[4]\tvalid_0's rmse: 41.0773\n",
      "[6]\tvalid_0's rmse: 40.6106\n",
      "[8]\tvalid_0's rmse: 40.2686\n",
      "[10]\tvalid_0's rmse: 39.9837\n",
      "[12]\tvalid_0's rmse: 39.7533\n",
      "[14]\tvalid_0's rmse: 39.5565\n",
      "[16]\tvalid_0's rmse: 39.3857\n",
      "[18]\tvalid_0's rmse: 39.223\n",
      "[20]\tvalid_0's rmse: 39.0826\n",
      "[22]\tvalid_0's rmse: 38.922\n",
      "[24]\tvalid_0's rmse: 38.7639\n",
      "[26]\tvalid_0's rmse: 38.6154\n",
      "[28]\tvalid_0's rmse: 38.4886\n",
      "[30]\tvalid_0's rmse: 38.3291\n",
      "[32]\tvalid_0's rmse: 38.2087\n",
      "[34]\tvalid_0's rmse: 38.0592\n",
      "[36]\tvalid_0's rmse: 37.9332\n",
      "[38]\tvalid_0's rmse: 37.8245\n",
      "[40]\tvalid_0's rmse: 37.6711\n",
      "[42]\tvalid_0's rmse: 37.5829\n",
      "[44]\tvalid_0's rmse: 37.462\n",
      "[46]\tvalid_0's rmse: 37.3705\n",
      "[48]\tvalid_0's rmse: 37.2906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 37.141423:  10%|#         | 1/10 [00:38<05:45, 38.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.199\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.199\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.138413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6734\n",
      "[4]\tvalid_0's rmse: 41.0558\n",
      "[6]\tvalid_0's rmse: 40.5792\n",
      "[8]\tvalid_0's rmse: 40.2231\n",
      "[10]\tvalid_0's rmse: 39.9419\n",
      "[12]\tvalid_0's rmse: 39.6997\n",
      "[14]\tvalid_0's rmse: 39.506\n",
      "[16]\tvalid_0's rmse: 39.3468\n",
      "[18]\tvalid_0's rmse: 39.1773\n",
      "[20]\tvalid_0's rmse: 39.026\n",
      "[22]\tvalid_0's rmse: 38.8893\n",
      "[24]\tvalid_0's rmse: 38.7421\n",
      "[26]\tvalid_0's rmse: 38.6057\n",
      "[28]\tvalid_0's rmse: 38.4502\n",
      "[30]\tvalid_0's rmse: 38.3188\n",
      "[32]\tvalid_0's rmse: 38.1747\n",
      "[34]\tvalid_0's rmse: 38.0589\n",
      "[36]\tvalid_0's rmse: 37.9108\n",
      "[38]\tvalid_0's rmse: 37.8082\n",
      "[40]\tvalid_0's rmse: 37.6681\n",
      "[42]\tvalid_0's rmse: 37.5454\n",
      "[44]\tvalid_0's rmse: 37.4384\n",
      "[46]\tvalid_0's rmse: 37.3191\n",
      "[48]\tvalid_0's rmse: 37.2291\n",
      "[50]\tvalid_0's rmse: 37.1402\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 37.140212:  20%|##        | 2/10 [01:27<05:56, 44.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.199342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7323\n",
      "[4]\tvalid_0's rmse: 41.1289\n",
      "[6]\tvalid_0's rmse: 40.6823\n",
      "[8]\tvalid_0's rmse: 40.3301\n",
      "[10]\tvalid_0's rmse: 40.046\n",
      "[12]\tvalid_0's rmse: 39.8164\n",
      "[14]\tvalid_0's rmse: 39.6349\n",
      "[16]\tvalid_0's rmse: 39.4557\n",
      "[18]\tvalid_0's rmse: 39.3046\n",
      "[20]\tvalid_0's rmse: 39.1527\n",
      "[22]\tvalid_0's rmse: 39.0152\n",
      "[24]\tvalid_0's rmse: 38.8772\n",
      "[26]\tvalid_0's rmse: 38.7471\n",
      "[28]\tvalid_0's rmse: 38.6274\n",
      "[30]\tvalid_0's rmse: 38.4844\n",
      "[32]\tvalid_0's rmse: 38.3588\n",
      "[34]\tvalid_0's rmse: 38.2373\n",
      "[36]\tvalid_0's rmse: 38.116\n",
      "[38]\tvalid_0's rmse: 38.0235\n",
      "[40]\tvalid_0's rmse: 37.8993\n",
      "[42]\tvalid_0's rmse: 37.7514\n",
      "[44]\tvalid_0's rmse: 37.6549\n",
      "[46]\tvalid_0's rmse: 37.5648\n",
      "[48]\tvalid_0's rmse: 37.4603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 37.140212:  30%|###       | 3/10 [02:08<05:01, 43.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.3839\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.3839\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.150105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.684\n",
      "[4]\tvalid_0's rmse: 41.0687\n",
      "[6]\tvalid_0's rmse: 40.5955\n",
      "[8]\tvalid_0's rmse: 40.2318\n",
      "[10]\tvalid_0's rmse: 39.9494\n",
      "[12]\tvalid_0's rmse: 39.7093\n",
      "[14]\tvalid_0's rmse: 39.5021\n",
      "[16]\tvalid_0's rmse: 39.3208\n",
      "[18]\tvalid_0's rmse: 39.1525\n",
      "[20]\tvalid_0's rmse: 39.004\n",
      "[22]\tvalid_0's rmse: 38.8447\n",
      "[24]\tvalid_0's rmse: 38.697\n",
      "[26]\tvalid_0's rmse: 38.5438\n",
      "[28]\tvalid_0's rmse: 38.4167\n",
      "[30]\tvalid_0's rmse: 38.2751\n",
      "[32]\tvalid_0's rmse: 38.1697\n",
      "[34]\tvalid_0's rmse: 38.0509\n",
      "[36]\tvalid_0's rmse: 37.9466\n",
      "[38]\tvalid_0's rmse: 37.7975\n",
      "[40]\tvalid_0's rmse: 37.6777\n",
      "[42]\tvalid_0's rmse: 37.5507\n",
      "[44]\tvalid_0's rmse: 37.4248\n",
      "[46]\tvalid_0's rmse: 37.3489\n",
      "[48]\tvalid_0's rmse: 37.2574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 37.140212:  40%|####      | 4/10 [03:00<04:39, 46.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1618\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "bagging, val_score: 37.140212:  40%|####      | 4/10 [03:00<04:39, 46.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7183\n",
      "[4]\tvalid_0's rmse: 41.1357\n",
      "[6]\tvalid_0's rmse: 40.6806\n",
      "[8]\tvalid_0's rmse: 40.3374\n",
      "[10]\tvalid_0's rmse: 40.0666\n",
      "[12]\tvalid_0's rmse: 39.8439\n",
      "[14]\tvalid_0's rmse: 39.6438\n",
      "[16]\tvalid_0's rmse: 39.4739\n",
      "[18]\tvalid_0's rmse: 39.3114\n",
      "[20]\tvalid_0's rmse: 39.1526\n",
      "[22]\tvalid_0's rmse: 39.0177\n",
      "[24]\tvalid_0's rmse: 38.8746\n",
      "[26]\tvalid_0's rmse: 38.7344\n",
      "[28]\tvalid_0's rmse: 38.6086\n",
      "[30]\tvalid_0's rmse: 38.4987\n",
      "[32]\tvalid_0's rmse: 38.3809\n",
      "[34]\tvalid_0's rmse: 38.2749\n",
      "[36]\tvalid_0's rmse: 38.1601\n",
      "[38]\tvalid_0's rmse: 38.0069\n",
      "[40]\tvalid_0's rmse: 37.9285\n",
      "[42]\tvalid_0's rmse: 37.8364\n",
      "[44]\tvalid_0's rmse: 37.7242\n",
      "[46]\tvalid_0's rmse: 37.6437\n",
      "[48]\tvalid_0's rmse: 37.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 37.140212:  50%|#####     | 5/10 [03:36<03:33, 42.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.4505\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.4505\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.182272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7264\n",
      "[4]\tvalid_0's rmse: 41.1169\n",
      "[6]\tvalid_0's rmse: 40.659\n",
      "[8]\tvalid_0's rmse: 40.3017\n",
      "[10]\tvalid_0's rmse: 40.016\n",
      "[12]\tvalid_0's rmse: 39.7823\n",
      "[14]\tvalid_0's rmse: 39.5987\n",
      "[16]\tvalid_0's rmse: 39.4361\n",
      "[18]\tvalid_0's rmse: 39.2853\n",
      "[20]\tvalid_0's rmse: 39.1235\n",
      "[22]\tvalid_0's rmse: 38.9839\n",
      "[24]\tvalid_0's rmse: 38.8591\n",
      "[26]\tvalid_0's rmse: 38.7023\n",
      "[28]\tvalid_0's rmse: 38.5726\n",
      "[30]\tvalid_0's rmse: 38.4471\n",
      "[32]\tvalid_0's rmse: 38.2991\n",
      "[34]\tvalid_0's rmse: 38.1592\n",
      "[36]\tvalid_0's rmse: 38.0408\n",
      "[38]\tvalid_0's rmse: 37.9166\n",
      "[40]\tvalid_0's rmse: 37.8354\n",
      "[42]\tvalid_0's rmse: 37.7502\n",
      "[44]\tvalid_0's rmse: 37.6334\n",
      "[46]\tvalid_0's rmse: 37.5113\n",
      "[48]\tvalid_0's rmse: 37.4114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 37.140212:  60%|######    | 6/10 [04:15<02:46, 41.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.3196\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.3196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "bagging, val_score: 37.140212:  60%|######    | 6/10 [04:15<02:46, 41.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.153711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7249\n",
      "[4]\tvalid_0's rmse: 41.1252\n",
      "[6]\tvalid_0's rmse: 40.6888\n",
      "[8]\tvalid_0's rmse: 40.3346\n",
      "[10]\tvalid_0's rmse: 40.059\n",
      "[12]\tvalid_0's rmse: 39.8402\n",
      "[14]\tvalid_0's rmse: 39.6415\n",
      "[16]\tvalid_0's rmse: 39.451\n",
      "[18]\tvalid_0's rmse: 39.2971\n",
      "[20]\tvalid_0's rmse: 39.1674\n",
      "[22]\tvalid_0's rmse: 39.036\n",
      "[24]\tvalid_0's rmse: 38.8954\n",
      "[26]\tvalid_0's rmse: 38.7581\n",
      "[28]\tvalid_0's rmse: 38.6284\n",
      "[30]\tvalid_0's rmse: 38.5071\n",
      "[32]\tvalid_0's rmse: 38.3988\n",
      "[34]\tvalid_0's rmse: 38.2822\n",
      "[36]\tvalid_0's rmse: 38.1856\n",
      "[38]\tvalid_0's rmse: 38.0964\n",
      "[40]\tvalid_0's rmse: 37.9679\n",
      "[42]\tvalid_0's rmse: 37.8622\n",
      "[44]\tvalid_0's rmse: 37.7287\n",
      "[46]\tvalid_0's rmse: 37.6426\n",
      "[48]\tvalid_0's rmse: 37.5471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 37.140212:  70%|#######   | 7/10 [04:55<02:02, 40.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.4618\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.4618\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.147078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7193\n",
      "[4]\tvalid_0's rmse: 41.1193\n",
      "[6]\tvalid_0's rmse: 40.667\n",
      "[8]\tvalid_0's rmse: 40.3099\n",
      "[10]\tvalid_0's rmse: 40.0282\n",
      "[12]\tvalid_0's rmse: 39.796\n",
      "[14]\tvalid_0's rmse: 39.5961\n",
      "[16]\tvalid_0's rmse: 39.4174\n",
      "[18]\tvalid_0's rmse: 39.2686\n",
      "[20]\tvalid_0's rmse: 39.1178\n",
      "[22]\tvalid_0's rmse: 38.9845\n",
      "[24]\tvalid_0's rmse: 38.8515\n",
      "[26]\tvalid_0's rmse: 38.7195\n",
      "[28]\tvalid_0's rmse: 38.6015\n",
      "[30]\tvalid_0's rmse: 38.4525\n",
      "[32]\tvalid_0's rmse: 38.3124\n",
      "[34]\tvalid_0's rmse: 38.183\n",
      "[36]\tvalid_0's rmse: 38.0893\n",
      "[38]\tvalid_0's rmse: 37.9946\n",
      "[40]\tvalid_0's rmse: 37.8448\n",
      "[42]\tvalid_0's rmse: 37.7348\n",
      "[44]\tvalid_0's rmse: 37.6102\n",
      "[46]\tvalid_0's rmse: 37.5258\n",
      "[48]\tvalid_0's rmse: 37.4383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 37.140212:  80%|########  | 8/10 [05:35<01:21, 40.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.3331\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.3331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "bagging, val_score: 37.140212:  80%|########  | 8/10 [05:35<01:21, 40.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7006\n",
      "[4]\tvalid_0's rmse: 41.0807\n",
      "[6]\tvalid_0's rmse: 40.626\n",
      "[8]\tvalid_0's rmse: 40.2725\n",
      "[10]\tvalid_0's rmse: 40.0083\n",
      "[12]\tvalid_0's rmse: 39.7767\n",
      "[14]\tvalid_0's rmse: 39.587\n",
      "[16]\tvalid_0's rmse: 39.4035\n",
      "[18]\tvalid_0's rmse: 39.2265\n",
      "[20]\tvalid_0's rmse: 39.0854\n",
      "[22]\tvalid_0's rmse: 38.9446\n",
      "[24]\tvalid_0's rmse: 38.7972\n",
      "[26]\tvalid_0's rmse: 38.6487\n",
      "[28]\tvalid_0's rmse: 38.5197\n",
      "[30]\tvalid_0's rmse: 38.3777\n",
      "[32]\tvalid_0's rmse: 38.2356\n",
      "[34]\tvalid_0's rmse: 38.1291\n",
      "[36]\tvalid_0's rmse: 37.9995\n",
      "[38]\tvalid_0's rmse: 37.8845\n",
      "[40]\tvalid_0's rmse: 37.7697\n",
      "[42]\tvalid_0's rmse: 37.628\n",
      "[44]\tvalid_0's rmse: 37.5306\n",
      "[46]\tvalid_0's rmse: 37.4224\n",
      "[48]\tvalid_0's rmse: 37.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 37.140212:  90%|######### | 9/10 [06:17<00:41, 41.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.214\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.214\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.188322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6878\n",
      "[4]\tvalid_0's rmse: 41.074\n",
      "[6]\tvalid_0's rmse: 40.6094\n",
      "[8]\tvalid_0's rmse: 40.2506\n",
      "[10]\tvalid_0's rmse: 39.9724\n",
      "[12]\tvalid_0's rmse: 39.7386\n",
      "[14]\tvalid_0's rmse: 39.5292\n",
      "[16]\tvalid_0's rmse: 39.353\n",
      "[18]\tvalid_0's rmse: 39.1837\n",
      "[20]\tvalid_0's rmse: 39.0375\n",
      "[22]\tvalid_0's rmse: 38.8767\n",
      "[24]\tvalid_0's rmse: 38.7307\n",
      "[26]\tvalid_0's rmse: 38.5841\n",
      "[28]\tvalid_0's rmse: 38.4488\n",
      "[30]\tvalid_0's rmse: 38.3073\n",
      "[32]\tvalid_0's rmse: 38.1619\n",
      "[34]\tvalid_0's rmse: 38.0222\n",
      "[36]\tvalid_0's rmse: 37.9023\n",
      "[38]\tvalid_0's rmse: 37.7838\n",
      "[40]\tvalid_0's rmse: 37.6843\n",
      "[42]\tvalid_0's rmse: 37.56\n",
      "[44]\tvalid_0's rmse: 37.4741\n",
      "[46]\tvalid_0's rmse: 37.3545\n",
      "[48]\tvalid_0's rmse: 37.2744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 37.140212: 100%|##########| 10/10 [07:10<00:00, 43.07s/it]\n",
      "feature_fraction_stage2, val_score: 37.140212:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1544\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1544\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.155434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6734\n",
      "[4]\tvalid_0's rmse: 41.0558\n",
      "[6]\tvalid_0's rmse: 40.5792\n",
      "[8]\tvalid_0's rmse: 40.2231\n",
      "[10]\tvalid_0's rmse: 39.9419\n",
      "[12]\tvalid_0's rmse: 39.6997\n",
      "[14]\tvalid_0's rmse: 39.506\n",
      "[16]\tvalid_0's rmse: 39.3468\n",
      "[18]\tvalid_0's rmse: 39.1773\n",
      "[20]\tvalid_0's rmse: 39.026\n",
      "[22]\tvalid_0's rmse: 38.8893\n",
      "[24]\tvalid_0's rmse: 38.7421\n",
      "[26]\tvalid_0's rmse: 38.6057\n",
      "[28]\tvalid_0's rmse: 38.4502\n",
      "[30]\tvalid_0's rmse: 38.3188\n",
      "[32]\tvalid_0's rmse: 38.1747\n",
      "[34]\tvalid_0's rmse: 38.0589\n",
      "[36]\tvalid_0's rmse: 37.9108\n",
      "[38]\tvalid_0's rmse: 37.8082\n",
      "[40]\tvalid_0's rmse: 37.6681\n",
      "[42]\tvalid_0's rmse: 37.5454\n",
      "[44]\tvalid_0's rmse: 37.4384\n",
      "[46]\tvalid_0's rmse: 37.3191\n",
      "[48]\tvalid_0's rmse: 37.2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 37.140212:  33%|###3      | 1/3 [00:48<01:36, 48.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1402\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "feature_fraction_stage2, val_score: 37.140212:  33%|###3      | 1/3 [00:48<01:36, 48.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.132387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6763\n",
      "[4]\tvalid_0's rmse: 41.0606\n",
      "[6]\tvalid_0's rmse: 40.5796\n",
      "[8]\tvalid_0's rmse: 40.2264\n",
      "[10]\tvalid_0's rmse: 39.9417\n",
      "[12]\tvalid_0's rmse: 39.7281\n",
      "[14]\tvalid_0's rmse: 39.5273\n",
      "[16]\tvalid_0's rmse: 39.3554\n",
      "[18]\tvalid_0's rmse: 39.1948\n",
      "[20]\tvalid_0's rmse: 39.0421\n",
      "[22]\tvalid_0's rmse: 38.8913\n",
      "[24]\tvalid_0's rmse: 38.7243\n",
      "[26]\tvalid_0's rmse: 38.5839\n",
      "[28]\tvalid_0's rmse: 38.4638\n",
      "[30]\tvalid_0's rmse: 38.3408\n",
      "[32]\tvalid_0's rmse: 38.1933\n",
      "[34]\tvalid_0's rmse: 38.0606\n",
      "[36]\tvalid_0's rmse: 37.934\n",
      "[38]\tvalid_0's rmse: 37.794\n",
      "[40]\tvalid_0's rmse: 37.6889\n",
      "[42]\tvalid_0's rmse: 37.5798\n",
      "[44]\tvalid_0's rmse: 37.4707\n",
      "[46]\tvalid_0's rmse: 37.3799\n",
      "[48]\tvalid_0's rmse: 37.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 37.140212:  67%|######6   | 2/3 [01:42<00:51, 51.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1802\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "feature_fraction_stage2, val_score: 37.140212:  67%|######6   | 2/3 [01:42<00:51, 51.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.142196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6763\n",
      "[4]\tvalid_0's rmse: 41.0606\n",
      "[6]\tvalid_0's rmse: 40.5796\n",
      "[8]\tvalid_0's rmse: 40.2264\n",
      "[10]\tvalid_0's rmse: 39.9417\n",
      "[12]\tvalid_0's rmse: 39.7281\n",
      "[14]\tvalid_0's rmse: 39.5273\n",
      "[16]\tvalid_0's rmse: 39.3554\n",
      "[18]\tvalid_0's rmse: 39.1948\n",
      "[20]\tvalid_0's rmse: 39.0421\n",
      "[22]\tvalid_0's rmse: 38.8913\n",
      "[24]\tvalid_0's rmse: 38.7243\n",
      "[26]\tvalid_0's rmse: 38.5839\n",
      "[28]\tvalid_0's rmse: 38.4638\n",
      "[30]\tvalid_0's rmse: 38.3408\n",
      "[32]\tvalid_0's rmse: 38.1933\n",
      "[34]\tvalid_0's rmse: 38.0606\n",
      "[36]\tvalid_0's rmse: 37.934\n",
      "[38]\tvalid_0's rmse: 37.794\n",
      "[40]\tvalid_0's rmse: 37.6889\n",
      "[42]\tvalid_0's rmse: 37.5798\n",
      "[44]\tvalid_0's rmse: 37.4707\n",
      "[46]\tvalid_0's rmse: 37.3799\n",
      "[48]\tvalid_0's rmse: 37.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 37.140212: 100%|##########| 3/3 [02:35<00:00, 52.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1802\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 37.140212: 100%|##########| 3/3 [02:35<00:00, 51.97s/it]\n",
      "regularization_factors, val_score: 37.140212:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.190080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6769\n",
      "[4]\tvalid_0's rmse: 41.0623\n",
      "[6]\tvalid_0's rmse: 40.5844\n",
      "[8]\tvalid_0's rmse: 40.2421\n",
      "[10]\tvalid_0's rmse: 39.9595\n",
      "[12]\tvalid_0's rmse: 39.7183\n",
      "[14]\tvalid_0's rmse: 39.5278\n",
      "[16]\tvalid_0's rmse: 39.3507\n",
      "[18]\tvalid_0's rmse: 39.182\n",
      "[20]\tvalid_0's rmse: 39.0416\n",
      "[22]\tvalid_0's rmse: 38.8979\n",
      "[24]\tvalid_0's rmse: 38.7491\n",
      "[26]\tvalid_0's rmse: 38.6083\n",
      "[28]\tvalid_0's rmse: 38.4804\n",
      "[30]\tvalid_0's rmse: 38.3478\n",
      "[32]\tvalid_0's rmse: 38.2112\n",
      "[34]\tvalid_0's rmse: 38.0659\n",
      "[36]\tvalid_0's rmse: 37.9413\n",
      "[38]\tvalid_0's rmse: 37.8277\n",
      "[40]\tvalid_0's rmse: 37.6888\n",
      "[42]\tvalid_0's rmse: 37.557\n",
      "[44]\tvalid_0's rmse: 37.4519\n",
      "[46]\tvalid_0's rmse: 37.3681\n",
      "[48]\tvalid_0's rmse: 37.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.140212:   5%|5         | 1/20 [00:57<18:18, 57.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1861\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1861\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.151271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6769\n",
      "[4]\tvalid_0's rmse: 41.0631\n",
      "[6]\tvalid_0's rmse: 40.5852\n",
      "[8]\tvalid_0's rmse: 40.2406\n",
      "[10]\tvalid_0's rmse: 39.9554\n",
      "[12]\tvalid_0's rmse: 39.7056\n",
      "[14]\tvalid_0's rmse: 39.513\n",
      "[16]\tvalid_0's rmse: 39.3398\n",
      "[18]\tvalid_0's rmse: 39.1675\n",
      "[20]\tvalid_0's rmse: 39.0018\n",
      "[22]\tvalid_0's rmse: 38.8505\n",
      "[24]\tvalid_0's rmse: 38.7075\n",
      "[26]\tvalid_0's rmse: 38.5967\n",
      "[28]\tvalid_0's rmse: 38.4683\n",
      "[30]\tvalid_0's rmse: 38.3408\n",
      "[32]\tvalid_0's rmse: 38.2196\n",
      "[34]\tvalid_0's rmse: 38.0943\n",
      "[36]\tvalid_0's rmse: 37.958\n",
      "[38]\tvalid_0's rmse: 37.8288\n",
      "[40]\tvalid_0's rmse: 37.7265\n",
      "[42]\tvalid_0's rmse: 37.6287\n",
      "[44]\tvalid_0's rmse: 37.5032\n",
      "[46]\tvalid_0's rmse: 37.3922\n",
      "[48]\tvalid_0's rmse: 37.2848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.140212:  10%|#         | 2/20 [01:54<17:09, 57.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1885\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1885\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6734\n",
      "[4]\tvalid_0's rmse: 41.0558\n",
      "[6]\tvalid_0's rmse: 40.5792\n",
      "[8]\tvalid_0's rmse: 40.2231\n",
      "[10]\tvalid_0's rmse: 39.9419\n",
      "[12]\tvalid_0's rmse: 39.6997\n",
      "[14]\tvalid_0's rmse: 39.506\n",
      "[16]\tvalid_0's rmse: 39.3468\n",
      "[18]\tvalid_0's rmse: 39.1773\n",
      "[20]\tvalid_0's rmse: 39.026\n",
      "[22]\tvalid_0's rmse: 38.8893\n",
      "[24]\tvalid_0's rmse: 38.7421\n",
      "[26]\tvalid_0's rmse: 38.6057\n",
      "[28]\tvalid_0's rmse: 38.4502\n",
      "[30]\tvalid_0's rmse: 38.3188\n",
      "[32]\tvalid_0's rmse: 38.1747\n",
      "[34]\tvalid_0's rmse: 38.0589\n",
      "[36]\tvalid_0's rmse: 37.9108\n",
      "[38]\tvalid_0's rmse: 37.8082\n",
      "[40]\tvalid_0's rmse: 37.6681\n",
      "[42]\tvalid_0's rmse: 37.5454\n",
      "[44]\tvalid_0's rmse: 37.4384\n",
      "[46]\tvalid_0's rmse: 37.3191\n",
      "[48]\tvalid_0's rmse: 37.2291\n",
      "[50]\tvalid_0's rmse: 37.1402\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.140212:  15%|#5        | 3/20 [02:40<14:47, 52.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.220530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6753\n",
      "[4]\tvalid_0's rmse: 41.0626\n",
      "[6]\tvalid_0's rmse: 40.5845\n",
      "[8]\tvalid_0's rmse: 40.2365\n",
      "[10]\tvalid_0's rmse: 39.9473\n",
      "[12]\tvalid_0's rmse: 39.7121\n",
      "[14]\tvalid_0's rmse: 39.5219\n",
      "[16]\tvalid_0's rmse: 39.3486\n",
      "[18]\tvalid_0's rmse: 39.1923\n",
      "[20]\tvalid_0's rmse: 39.0463\n",
      "[22]\tvalid_0's rmse: 38.9044\n",
      "[24]\tvalid_0's rmse: 38.7539\n",
      "[26]\tvalid_0's rmse: 38.608\n",
      "[28]\tvalid_0's rmse: 38.5026\n",
      "[30]\tvalid_0's rmse: 38.3441\n",
      "[32]\tvalid_0's rmse: 38.209\n",
      "[34]\tvalid_0's rmse: 38.0798\n",
      "[36]\tvalid_0's rmse: 37.9592\n",
      "[38]\tvalid_0's rmse: 37.8504\n",
      "[40]\tvalid_0's rmse: 37.6924\n",
      "[42]\tvalid_0's rmse: 37.541\n",
      "[44]\tvalid_0's rmse: 37.4336\n",
      "[46]\tvalid_0's rmse: 37.3413\n",
      "[48]\tvalid_0's rmse: 37.2397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.140212:  20%|##        | 4/20 [03:29<13:31, 50.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1443\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 37.140212:  20%|##        | 4/20 [03:29<13:31, 50.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.147300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6753\n",
      "[4]\tvalid_0's rmse: 41.062\n",
      "[6]\tvalid_0's rmse: 40.5803\n",
      "[8]\tvalid_0's rmse: 40.2308\n",
      "[10]\tvalid_0's rmse: 39.9522\n",
      "[12]\tvalid_0's rmse: 39.7155\n",
      "[14]\tvalid_0's rmse: 39.5315\n",
      "[16]\tvalid_0's rmse: 39.364\n",
      "[18]\tvalid_0's rmse: 39.2036\n",
      "[20]\tvalid_0's rmse: 39.0452\n",
      "[22]\tvalid_0's rmse: 38.8871\n",
      "[24]\tvalid_0's rmse: 38.751\n",
      "[26]\tvalid_0's rmse: 38.6092\n",
      "[28]\tvalid_0's rmse: 38.4819\n",
      "[30]\tvalid_0's rmse: 38.3274\n",
      "[32]\tvalid_0's rmse: 38.1836\n",
      "[34]\tvalid_0's rmse: 38.0679\n",
      "[36]\tvalid_0's rmse: 37.9252\n",
      "[38]\tvalid_0's rmse: 37.821\n",
      "[40]\tvalid_0's rmse: 37.6672\n",
      "[42]\tvalid_0's rmse: 37.5392\n",
      "[44]\tvalid_0's rmse: 37.4514\n",
      "[46]\tvalid_0's rmse: 37.342\n",
      "[48]\tvalid_0's rmse: 37.2456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.140212:  25%|##5       | 5/20 [04:19<12:38, 50.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1513\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1513\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.149264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6727\n",
      "[4]\tvalid_0's rmse: 41.0552\n",
      "[6]\tvalid_0's rmse: 40.5787\n",
      "[8]\tvalid_0's rmse: 40.2217\n",
      "[10]\tvalid_0's rmse: 39.9403\n",
      "[12]\tvalid_0's rmse: 39.7105\n",
      "[14]\tvalid_0's rmse: 39.5034\n",
      "[16]\tvalid_0's rmse: 39.3298\n",
      "[18]\tvalid_0's rmse: 39.1615\n",
      "[20]\tvalid_0's rmse: 39.0105\n",
      "[22]\tvalid_0's rmse: 38.8497\n",
      "[24]\tvalid_0's rmse: 38.7053\n",
      "[26]\tvalid_0's rmse: 38.5816\n",
      "[28]\tvalid_0's rmse: 38.4644\n",
      "[30]\tvalid_0's rmse: 38.3306\n",
      "[32]\tvalid_0's rmse: 38.1801\n",
      "[34]\tvalid_0's rmse: 38.0333\n",
      "[36]\tvalid_0's rmse: 37.9128\n",
      "[38]\tvalid_0's rmse: 37.7793\n",
      "[40]\tvalid_0's rmse: 37.6595\n",
      "[42]\tvalid_0's rmse: 37.547\n",
      "[44]\tvalid_0's rmse: 37.4123\n",
      "[46]\tvalid_0's rmse: 37.2909\n",
      "[48]\tvalid_0's rmse: 37.2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.111480:  30%|###       | 6/20 [05:04<11:18, 48.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1115\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1115\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.137535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6735\n",
      "[4]\tvalid_0's rmse: 41.058\n",
      "[6]\tvalid_0's rmse: 40.5773\n",
      "[8]\tvalid_0's rmse: 40.2309\n",
      "[10]\tvalid_0's rmse: 39.9567\n",
      "[12]\tvalid_0's rmse: 39.7259\n",
      "[14]\tvalid_0's rmse: 39.5238\n",
      "[16]\tvalid_0's rmse: 39.3464\n",
      "[18]\tvalid_0's rmse: 39.1942\n",
      "[20]\tvalid_0's rmse: 39.0326\n",
      "[22]\tvalid_0's rmse: 38.8722\n",
      "[24]\tvalid_0's rmse: 38.7239\n",
      "[26]\tvalid_0's rmse: 38.5679\n",
      "[28]\tvalid_0's rmse: 38.4567\n",
      "[30]\tvalid_0's rmse: 38.3031\n",
      "[32]\tvalid_0's rmse: 38.1907\n",
      "[34]\tvalid_0's rmse: 38.0867\n",
      "[36]\tvalid_0's rmse: 37.9404\n",
      "[38]\tvalid_0's rmse: 37.8377\n",
      "[40]\tvalid_0's rmse: 37.7409\n",
      "[42]\tvalid_0's rmse: 37.6197\n",
      "[44]\tvalid_0's rmse: 37.4938\n",
      "[46]\tvalid_0's rmse: 37.3788\n",
      "[48]\tvalid_0's rmse: 37.2961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.111480:  35%|###5      | 7/20 [05:48<10:12, 47.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.2142\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.2142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 37.111480:  35%|###5      | 7/20 [05:48<10:12, 47.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.142688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6754\n",
      "[4]\tvalid_0's rmse: 41.0627\n",
      "[6]\tvalid_0's rmse: 40.5847\n",
      "[8]\tvalid_0's rmse: 40.2367\n",
      "[10]\tvalid_0's rmse: 39.9475\n",
      "[12]\tvalid_0's rmse: 39.7123\n",
      "[14]\tvalid_0's rmse: 39.5221\n",
      "[16]\tvalid_0's rmse: 39.3478\n",
      "[18]\tvalid_0's rmse: 39.1918\n",
      "[20]\tvalid_0's rmse: 39.0465\n",
      "[22]\tvalid_0's rmse: 38.9041\n",
      "[24]\tvalid_0's rmse: 38.7521\n",
      "[26]\tvalid_0's rmse: 38.6057\n",
      "[28]\tvalid_0's rmse: 38.4808\n",
      "[30]\tvalid_0's rmse: 38.357\n",
      "[32]\tvalid_0's rmse: 38.2356\n",
      "[34]\tvalid_0's rmse: 38.1215\n",
      "[36]\tvalid_0's rmse: 38.0078\n",
      "[38]\tvalid_0's rmse: 37.8779\n",
      "[40]\tvalid_0's rmse: 37.7408\n",
      "[42]\tvalid_0's rmse: 37.6319\n",
      "[44]\tvalid_0's rmse: 37.5314\n",
      "[46]\tvalid_0's rmse: 37.4305\n",
      "[48]\tvalid_0's rmse: 37.3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.111480:  40%|####      | 8/20 [06:32<09:13, 46.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.2408\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.2408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 37.111480:  40%|####      | 8/20 [06:32<09:13, 46.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6727\n",
      "[4]\tvalid_0's rmse: 41.0552\n",
      "[6]\tvalid_0's rmse: 40.5787\n",
      "[8]\tvalid_0's rmse: 40.2217\n",
      "[10]\tvalid_0's rmse: 39.9403\n",
      "[12]\tvalid_0's rmse: 39.7105\n",
      "[14]\tvalid_0's rmse: 39.5034\n",
      "[16]\tvalid_0's rmse: 39.3298\n",
      "[18]\tvalid_0's rmse: 39.1615\n",
      "[20]\tvalid_0's rmse: 39.0105\n",
      "[22]\tvalid_0's rmse: 38.8497\n",
      "[24]\tvalid_0's rmse: 38.7053\n",
      "[26]\tvalid_0's rmse: 38.5816\n",
      "[28]\tvalid_0's rmse: 38.4644\n",
      "[30]\tvalid_0's rmse: 38.3306\n",
      "[32]\tvalid_0's rmse: 38.1801\n",
      "[34]\tvalid_0's rmse: 38.0333\n",
      "[36]\tvalid_0's rmse: 37.9128\n",
      "[38]\tvalid_0's rmse: 37.7793\n",
      "[40]\tvalid_0's rmse: 37.6595\n",
      "[42]\tvalid_0's rmse: 37.547\n",
      "[44]\tvalid_0's rmse: 37.4123\n",
      "[46]\tvalid_0's rmse: 37.2909\n",
      "[48]\tvalid_0's rmse: 37.2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.111460:  45%|####5     | 9/20 [07:16<08:21, 45.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1115\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 37.111460:  45%|####5     | 9/20 [07:16<08:21, 45.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6762\n",
      "[4]\tvalid_0's rmse: 41.0637\n",
      "[6]\tvalid_0's rmse: 40.5928\n",
      "[8]\tvalid_0's rmse: 40.2496\n",
      "[10]\tvalid_0's rmse: 39.9744\n",
      "[12]\tvalid_0's rmse: 39.7316\n",
      "[14]\tvalid_0's rmse: 39.5434\n",
      "[16]\tvalid_0's rmse: 39.3649\n",
      "[18]\tvalid_0's rmse: 39.1961\n",
      "[20]\tvalid_0's rmse: 39.0523\n",
      "[22]\tvalid_0's rmse: 38.8977\n",
      "[24]\tvalid_0's rmse: 38.7376\n",
      "[26]\tvalid_0's rmse: 38.6152\n",
      "[28]\tvalid_0's rmse: 38.4777\n",
      "[30]\tvalid_0's rmse: 38.3614\n",
      "[32]\tvalid_0's rmse: 38.2371\n",
      "[34]\tvalid_0's rmse: 38.0587\n",
      "[36]\tvalid_0's rmse: 37.9205\n",
      "[38]\tvalid_0's rmse: 37.8172\n",
      "[40]\tvalid_0's rmse: 37.699\n",
      "[42]\tvalid_0's rmse: 37.5849\n",
      "[44]\tvalid_0's rmse: 37.4933\n",
      "[46]\tvalid_0's rmse: 37.3772\n",
      "[48]\tvalid_0's rmse: 37.2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.111460:  50%|#####     | 10/20 [08:01<07:32, 45.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1679\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 37.111460:  50%|#####     | 10/20 [08:01<07:32, 45.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.139650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6734\n",
      "[4]\tvalid_0's rmse: 41.0558\n",
      "[6]\tvalid_0's rmse: 40.5792\n",
      "[8]\tvalid_0's rmse: 40.2231\n",
      "[10]\tvalid_0's rmse: 39.9419\n",
      "[12]\tvalid_0's rmse: 39.6997\n",
      "[14]\tvalid_0's rmse: 39.506\n",
      "[16]\tvalid_0's rmse: 39.3468\n",
      "[18]\tvalid_0's rmse: 39.1773\n",
      "[20]\tvalid_0's rmse: 39.026\n",
      "[22]\tvalid_0's rmse: 38.8893\n",
      "[24]\tvalid_0's rmse: 38.7421\n",
      "[26]\tvalid_0's rmse: 38.6057\n",
      "[28]\tvalid_0's rmse: 38.4502\n",
      "[30]\tvalid_0's rmse: 38.3188\n",
      "[32]\tvalid_0's rmse: 38.1747\n",
      "[34]\tvalid_0's rmse: 38.0589\n",
      "[36]\tvalid_0's rmse: 37.9109\n",
      "[38]\tvalid_0's rmse: 37.8082\n",
      "[40]\tvalid_0's rmse: 37.6681\n",
      "[42]\tvalid_0's rmse: 37.5454\n",
      "[44]\tvalid_0's rmse: 37.4384\n",
      "[46]\tvalid_0's rmse: 37.3191\n",
      "[48]\tvalid_0's rmse: 37.2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.111460:  55%|#####5    | 11/20 [08:46<06:46, 45.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1402\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 37.111460:  55%|#####5    | 11/20 [08:46<06:46, 45.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.139617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6727\n",
      "[4]\tvalid_0's rmse: 41.0552\n",
      "[6]\tvalid_0's rmse: 40.5787\n",
      "[8]\tvalid_0's rmse: 40.2217\n",
      "[10]\tvalid_0's rmse: 39.9403\n",
      "[12]\tvalid_0's rmse: 39.7105\n",
      "[14]\tvalid_0's rmse: 39.5034\n",
      "[16]\tvalid_0's rmse: 39.3298\n",
      "[18]\tvalid_0's rmse: 39.1615\n",
      "[20]\tvalid_0's rmse: 39.0105\n",
      "[22]\tvalid_0's rmse: 38.8497\n",
      "[24]\tvalid_0's rmse: 38.7053\n",
      "[26]\tvalid_0's rmse: 38.5816\n",
      "[28]\tvalid_0's rmse: 38.4644\n",
      "[30]\tvalid_0's rmse: 38.3306\n",
      "[32]\tvalid_0's rmse: 38.1801\n",
      "[34]\tvalid_0's rmse: 38.0333\n",
      "[36]\tvalid_0's rmse: 37.9128\n",
      "[38]\tvalid_0's rmse: 37.7793\n",
      "[40]\tvalid_0's rmse: 37.6595\n",
      "[42]\tvalid_0's rmse: 37.547\n",
      "[44]\tvalid_0's rmse: 37.4123\n",
      "[46]\tvalid_0's rmse: 37.2909\n",
      "[48]\tvalid_0's rmse: 37.2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.111460:  60%|######    | 12/20 [09:29<05:57, 44.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1115\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1115\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6727\n",
      "[4]\tvalid_0's rmse: 41.0552\n",
      "[6]\tvalid_0's rmse: 40.5787\n",
      "[8]\tvalid_0's rmse: 40.2217\n",
      "[10]\tvalid_0's rmse: 39.9403\n",
      "[12]\tvalid_0's rmse: 39.7105\n",
      "[14]\tvalid_0's rmse: 39.5034\n",
      "[16]\tvalid_0's rmse: 39.3298\n",
      "[18]\tvalid_0's rmse: 39.1615\n",
      "[20]\tvalid_0's rmse: 39.0105\n",
      "[22]\tvalid_0's rmse: 38.8497\n",
      "[24]\tvalid_0's rmse: 38.7053\n",
      "[26]\tvalid_0's rmse: 38.5816\n",
      "[28]\tvalid_0's rmse: 38.4644\n",
      "[30]\tvalid_0's rmse: 38.3306\n",
      "[32]\tvalid_0's rmse: 38.1801\n",
      "[34]\tvalid_0's rmse: 38.0333\n",
      "[36]\tvalid_0's rmse: 37.9128\n",
      "[38]\tvalid_0's rmse: 37.7793\n",
      "[40]\tvalid_0's rmse: 37.6595\n",
      "[42]\tvalid_0's rmse: 37.547\n",
      "[44]\tvalid_0's rmse: 37.4123\n",
      "[46]\tvalid_0's rmse: 37.2909\n",
      "[48]\tvalid_0's rmse: 37.2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.111460:  65%|######5   | 13/20 [10:13<05:09, 44.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1115\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1115\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6734\n",
      "[4]\tvalid_0's rmse: 41.0558\n",
      "[6]\tvalid_0's rmse: 40.5792\n",
      "[8]\tvalid_0's rmse: 40.2231\n",
      "[10]\tvalid_0's rmse: 39.9419\n",
      "[12]\tvalid_0's rmse: 39.6997\n",
      "[14]\tvalid_0's rmse: 39.506\n",
      "[16]\tvalid_0's rmse: 39.3468\n",
      "[18]\tvalid_0's rmse: 39.1773\n",
      "[20]\tvalid_0's rmse: 39.026\n",
      "[22]\tvalid_0's rmse: 38.8893\n",
      "[24]\tvalid_0's rmse: 38.7421\n",
      "[26]\tvalid_0's rmse: 38.6057\n",
      "[28]\tvalid_0's rmse: 38.4502\n",
      "[30]\tvalid_0's rmse: 38.3188\n",
      "[32]\tvalid_0's rmse: 38.1747\n",
      "[34]\tvalid_0's rmse: 38.0589\n",
      "[36]\tvalid_0's rmse: 37.9108\n",
      "[38]\tvalid_0's rmse: 37.8082\n",
      "[40]\tvalid_0's rmse: 37.6681\n",
      "[42]\tvalid_0's rmse: 37.5454\n",
      "[44]\tvalid_0's rmse: 37.4384\n",
      "[46]\tvalid_0's rmse: 37.3191\n",
      "[48]\tvalid_0's rmse: 37.2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.111460:  70%|#######   | 14/20 [10:57<04:26, 44.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1402\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 37.111460:  70%|#######   | 14/20 [10:57<04:26, 44.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.148744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6727\n",
      "[4]\tvalid_0's rmse: 41.0552\n",
      "[6]\tvalid_0's rmse: 40.5787\n",
      "[8]\tvalid_0's rmse: 40.2217\n",
      "[10]\tvalid_0's rmse: 39.9403\n",
      "[12]\tvalid_0's rmse: 39.7105\n",
      "[14]\tvalid_0's rmse: 39.5034\n",
      "[16]\tvalid_0's rmse: 39.3298\n",
      "[18]\tvalid_0's rmse: 39.1615\n",
      "[20]\tvalid_0's rmse: 39.0105\n",
      "[22]\tvalid_0's rmse: 38.8497\n",
      "[24]\tvalid_0's rmse: 38.7053\n",
      "[26]\tvalid_0's rmse: 38.5816\n",
      "[28]\tvalid_0's rmse: 38.4644\n",
      "[30]\tvalid_0's rmse: 38.3306\n",
      "[32]\tvalid_0's rmse: 38.1801\n",
      "[34]\tvalid_0's rmse: 38.0333\n",
      "[36]\tvalid_0's rmse: 37.9128\n",
      "[38]\tvalid_0's rmse: 37.7793\n",
      "[40]\tvalid_0's rmse: 37.6595\n",
      "[42]\tvalid_0's rmse: 37.547\n",
      "[44]\tvalid_0's rmse: 37.4123\n",
      "[46]\tvalid_0's rmse: 37.2909\n",
      "[48]\tvalid_0's rmse: 37.2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.111460:  75%|#######5  | 15/20 [11:42<03:41, 44.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1115\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1115\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.160795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6727\n",
      "[4]\tvalid_0's rmse: 41.0552\n",
      "[6]\tvalid_0's rmse: 40.5787\n",
      "[8]\tvalid_0's rmse: 40.2217\n",
      "[10]\tvalid_0's rmse: 39.9403\n",
      "[12]\tvalid_0's rmse: 39.7105\n",
      "[14]\tvalid_0's rmse: 39.5034\n",
      "[16]\tvalid_0's rmse: 39.3298\n",
      "[18]\tvalid_0's rmse: 39.1615\n",
      "[20]\tvalid_0's rmse: 39.0105\n",
      "[22]\tvalid_0's rmse: 38.8497\n",
      "[24]\tvalid_0's rmse: 38.7053\n",
      "[26]\tvalid_0's rmse: 38.5816\n",
      "[28]\tvalid_0's rmse: 38.4644\n",
      "[30]\tvalid_0's rmse: 38.3306\n",
      "[32]\tvalid_0's rmse: 38.1801\n",
      "[34]\tvalid_0's rmse: 38.0333\n",
      "[36]\tvalid_0's rmse: 37.9128\n",
      "[38]\tvalid_0's rmse: 37.7793\n",
      "[40]\tvalid_0's rmse: 37.6595\n",
      "[42]\tvalid_0's rmse: 37.547\n",
      "[44]\tvalid_0's rmse: 37.4124\n",
      "[46]\tvalid_0's rmse: 37.2909\n",
      "[48]\tvalid_0's rmse: 37.2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.111460:  80%|########  | 16/20 [12:26<02:57, 44.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1115\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 37.111460:  80%|########  | 16/20 [12:26<02:57, 44.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.150797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6762\n",
      "[4]\tvalid_0's rmse: 41.0637\n",
      "[6]\tvalid_0's rmse: 40.5924\n",
      "[8]\tvalid_0's rmse: 40.2462\n",
      "[10]\tvalid_0's rmse: 39.9689\n",
      "[12]\tvalid_0's rmse: 39.7294\n",
      "[14]\tvalid_0's rmse: 39.5251\n",
      "[16]\tvalid_0's rmse: 39.343\n",
      "[18]\tvalid_0's rmse: 39.1976\n",
      "[20]\tvalid_0's rmse: 39.0394\n",
      "[22]\tvalid_0's rmse: 38.8923\n",
      "[24]\tvalid_0's rmse: 38.7483\n",
      "[26]\tvalid_0's rmse: 38.5897\n",
      "[28]\tvalid_0's rmse: 38.4473\n",
      "[30]\tvalid_0's rmse: 38.3055\n",
      "[32]\tvalid_0's rmse: 38.1446\n",
      "[34]\tvalid_0's rmse: 37.9685\n",
      "[36]\tvalid_0's rmse: 37.8598\n",
      "[38]\tvalid_0's rmse: 37.7322\n",
      "[40]\tvalid_0's rmse: 37.6258\n",
      "[42]\tvalid_0's rmse: 37.4957\n",
      "[44]\tvalid_0's rmse: 37.3921\n",
      "[46]\tvalid_0's rmse: 37.3066\n",
      "[48]\tvalid_0's rmse: 37.2034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.077318:  85%|########5 | 17/20 [13:11<02:13, 44.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.0773\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 37.077318:  85%|########5 | 17/20 [13:11<02:13, 44.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7032\n",
      "[4]\tvalid_0's rmse: 41.1042\n",
      "[6]\tvalid_0's rmse: 40.6441\n",
      "[8]\tvalid_0's rmse: 40.3018\n",
      "[10]\tvalid_0's rmse: 40.0176\n",
      "[12]\tvalid_0's rmse: 39.7879\n",
      "[14]\tvalid_0's rmse: 39.5942\n",
      "[16]\tvalid_0's rmse: 39.4238\n",
      "[18]\tvalid_0's rmse: 39.2706\n",
      "[20]\tvalid_0's rmse: 39.13\n",
      "[22]\tvalid_0's rmse: 38.9804\n",
      "[24]\tvalid_0's rmse: 38.8367\n",
      "[26]\tvalid_0's rmse: 38.6931\n",
      "[28]\tvalid_0's rmse: 38.5677\n",
      "[30]\tvalid_0's rmse: 38.4381\n",
      "[32]\tvalid_0's rmse: 38.3035\n",
      "[34]\tvalid_0's rmse: 38.1736\n",
      "[36]\tvalid_0's rmse: 38.0387\n",
      "[38]\tvalid_0's rmse: 37.9048\n",
      "[40]\tvalid_0's rmse: 37.8095\n",
      "[42]\tvalid_0's rmse: 37.6849\n",
      "[44]\tvalid_0's rmse: 37.5844\n",
      "[46]\tvalid_0's rmse: 37.4873\n",
      "[48]\tvalid_0's rmse: 37.3829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.077318:  90%|######### | 18/20 [13:57<01:29, 44.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.2831\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.2831\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.142772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6764\n",
      "[4]\tvalid_0's rmse: 41.0634\n",
      "[6]\tvalid_0's rmse: 40.592\n",
      "[8]\tvalid_0's rmse: 40.2445\n",
      "[10]\tvalid_0's rmse: 39.9671\n",
      "[12]\tvalid_0's rmse: 39.725\n",
      "[14]\tvalid_0's rmse: 39.5196\n",
      "[16]\tvalid_0's rmse: 39.3589\n",
      "[18]\tvalid_0's rmse: 39.1839\n",
      "[20]\tvalid_0's rmse: 39.0168\n",
      "[22]\tvalid_0's rmse: 38.881\n",
      "[24]\tvalid_0's rmse: 38.7394\n",
      "[26]\tvalid_0's rmse: 38.5929\n",
      "[28]\tvalid_0's rmse: 38.4559\n",
      "[30]\tvalid_0's rmse: 38.3208\n",
      "[32]\tvalid_0's rmse: 38.184\n",
      "[34]\tvalid_0's rmse: 38.0092\n",
      "[36]\tvalid_0's rmse: 37.8988\n",
      "[38]\tvalid_0's rmse: 37.7842\n",
      "[40]\tvalid_0's rmse: 37.6701\n",
      "[42]\tvalid_0's rmse: 37.5868\n",
      "[44]\tvalid_0's rmse: 37.4621\n",
      "[46]\tvalid_0's rmse: 37.3641\n",
      "[48]\tvalid_0's rmse: 37.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.077318:  95%|#########5| 19/20 [15:34<01:00, 60.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.157\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.157\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.139575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6769\n",
      "[4]\tvalid_0's rmse: 41.0631\n",
      "[6]\tvalid_0's rmse: 40.5852\n",
      "[8]\tvalid_0's rmse: 40.2406\n",
      "[10]\tvalid_0's rmse: 39.959\n",
      "[12]\tvalid_0's rmse: 39.7096\n",
      "[14]\tvalid_0's rmse: 39.5174\n",
      "[16]\tvalid_0's rmse: 39.3457\n",
      "[18]\tvalid_0's rmse: 39.1737\n",
      "[20]\tvalid_0's rmse: 39.0078\n",
      "[22]\tvalid_0's rmse: 38.8592\n",
      "[24]\tvalid_0's rmse: 38.7203\n",
      "[26]\tvalid_0's rmse: 38.5455\n",
      "[28]\tvalid_0's rmse: 38.4265\n",
      "[30]\tvalid_0's rmse: 38.2919\n",
      "[32]\tvalid_0's rmse: 38.1541\n",
      "[34]\tvalid_0's rmse: 38.0256\n",
      "[36]\tvalid_0's rmse: 37.8743\n",
      "[38]\tvalid_0's rmse: 37.7748\n",
      "[40]\tvalid_0's rmse: 37.6434\n",
      "[42]\tvalid_0's rmse: 37.5696\n",
      "[44]\tvalid_0's rmse: 37.4563\n",
      "[46]\tvalid_0's rmse: 37.3354\n",
      "[48]\tvalid_0's rmse: 37.2501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 37.077318: 100%|##########| 20/20 [16:15<00:00, 48.77s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1378\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "min_data_in_leaf, val_score: 37.077318:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.185647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7202\n",
      "[4]\tvalid_0's rmse: 41.1272\n",
      "[6]\tvalid_0's rmse: 40.691\n",
      "[8]\tvalid_0's rmse: 40.3567\n",
      "[10]\tvalid_0's rmse: 40.096\n",
      "[12]\tvalid_0's rmse: 39.8648\n",
      "[14]\tvalid_0's rmse: 39.6754\n",
      "[16]\tvalid_0's rmse: 39.5094\n",
      "[18]\tvalid_0's rmse: 39.3613\n",
      "[20]\tvalid_0's rmse: 39.2119\n",
      "[22]\tvalid_0's rmse: 39.0692\n",
      "[24]\tvalid_0's rmse: 38.9246\n",
      "[26]\tvalid_0's rmse: 38.7792\n",
      "[28]\tvalid_0's rmse: 38.654\n",
      "[30]\tvalid_0's rmse: 38.5505\n",
      "[32]\tvalid_0's rmse: 38.423\n",
      "[34]\tvalid_0's rmse: 38.2931\n",
      "[36]\tvalid_0's rmse: 38.1658\n",
      "[38]\tvalid_0's rmse: 38.0363\n",
      "[40]\tvalid_0's rmse: 37.9263\n",
      "[42]\tvalid_0's rmse: 37.8275\n",
      "[44]\tvalid_0's rmse: 37.7131\n",
      "[46]\tvalid_0's rmse: 37.5853\n",
      "[48]\tvalid_0's rmse: 37.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 37.077318:  20%|##        | 1/5 [17:56<1:11:43, 1075.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.3986\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.3986\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.169619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6851\n",
      "[4]\tvalid_0's rmse: 41.0708\n",
      "[6]\tvalid_0's rmse: 40.5991\n",
      "[8]\tvalid_0's rmse: 40.25\n",
      "[10]\tvalid_0's rmse: 39.9817\n",
      "[12]\tvalid_0's rmse: 39.7513\n",
      "[14]\tvalid_0's rmse: 39.5526\n",
      "[16]\tvalid_0's rmse: 39.3638\n",
      "[18]\tvalid_0's rmse: 39.2103\n",
      "[20]\tvalid_0's rmse: 39.0653\n",
      "[22]\tvalid_0's rmse: 38.9148\n",
      "[24]\tvalid_0's rmse: 38.7709\n",
      "[26]\tvalid_0's rmse: 38.6198\n",
      "[28]\tvalid_0's rmse: 38.4993\n",
      "[30]\tvalid_0's rmse: 38.3615\n",
      "[32]\tvalid_0's rmse: 38.2127\n",
      "[34]\tvalid_0's rmse: 38.1038\n",
      "[36]\tvalid_0's rmse: 37.9568\n",
      "[38]\tvalid_0's rmse: 37.83\n",
      "[40]\tvalid_0's rmse: 37.719\n",
      "[42]\tvalid_0's rmse: 37.593\n",
      "[44]\tvalid_0's rmse: 37.4805\n",
      "[46]\tvalid_0's rmse: 37.3756\n",
      "[48]\tvalid_0's rmse: 37.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 37.077318:  40%|####      | 2/5 [18:45<23:35, 471.91s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.1829\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.1829\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.938253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.6559\n",
      "[4]\tvalid_0's rmse: 41.0246\n",
      "[6]\tvalid_0's rmse: 40.5386\n",
      "[8]\tvalid_0's rmse: 40.1781\n",
      "[10]\tvalid_0's rmse: 39.8877\n",
      "[12]\tvalid_0's rmse: 39.6456\n",
      "[14]\tvalid_0's rmse: 39.4353\n",
      "[16]\tvalid_0's rmse: 39.2482\n",
      "[18]\tvalid_0's rmse: 39.0697\n",
      "[20]\tvalid_0's rmse: 38.9273\n",
      "[22]\tvalid_0's rmse: 38.7385\n",
      "[24]\tvalid_0's rmse: 38.597\n",
      "[26]\tvalid_0's rmse: 38.4576\n",
      "[28]\tvalid_0's rmse: 38.308\n",
      "[30]\tvalid_0's rmse: 38.1627\n",
      "[32]\tvalid_0's rmse: 38.0278\n",
      "[34]\tvalid_0's rmse: 37.8706\n",
      "[36]\tvalid_0's rmse: 37.7311\n",
      "[38]\tvalid_0's rmse: 37.606\n",
      "[40]\tvalid_0's rmse: 37.5126\n",
      "[42]\tvalid_0's rmse: 37.3903\n",
      "[44]\tvalid_0's rmse: 37.2856\n",
      "[46]\tvalid_0's rmse: 37.1916\n",
      "[48]\tvalid_0's rmse: 37.0826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 36.993978:  60%|######    | 3/5 [19:43<09:26, 283.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 36.994\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 36.994\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.131962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.7586\n",
      "[4]\tvalid_0's rmse: 41.1933\n",
      "[6]\tvalid_0's rmse: 40.7724\n",
      "[8]\tvalid_0's rmse: 40.4546\n",
      "[10]\tvalid_0's rmse: 40.197\n",
      "[12]\tvalid_0's rmse: 39.9917\n",
      "[14]\tvalid_0's rmse: 39.8124\n",
      "[16]\tvalid_0's rmse: 39.6427\n",
      "[18]\tvalid_0's rmse: 39.5043\n",
      "[20]\tvalid_0's rmse: 39.3731\n",
      "[22]\tvalid_0's rmse: 39.2374\n",
      "[24]\tvalid_0's rmse: 39.1253\n",
      "[26]\tvalid_0's rmse: 39.0142\n",
      "[28]\tvalid_0's rmse: 38.8967\n",
      "[30]\tvalid_0's rmse: 38.7944\n",
      "[32]\tvalid_0's rmse: 38.6684\n",
      "[34]\tvalid_0's rmse: 38.5432\n",
      "[36]\tvalid_0's rmse: 38.3978\n",
      "[38]\tvalid_0's rmse: 38.3095\n",
      "[40]\tvalid_0's rmse: 38.1984\n",
      "[42]\tvalid_0's rmse: 38.0876\n",
      "[44]\tvalid_0's rmse: 38.0189\n",
      "[46]\tvalid_0's rmse: 37.9115\n",
      "[48]\tvalid_0's rmse: 37.8243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 36.993978:  80%|########  | 4/5 [20:31<03:10, 190.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 37.7539\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 37.7539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "min_data_in_leaf, val_score: 36.993978:  80%|########  | 4/5 [20:31<03:10, 190.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.629\n",
      "[4]\tvalid_0's rmse: 40.9801\n",
      "[6]\tvalid_0's rmse: 40.4789\n",
      "[8]\tvalid_0's rmse: 40.1106\n",
      "[10]\tvalid_0's rmse: 39.8158\n",
      "[12]\tvalid_0's rmse: 39.5539\n",
      "[14]\tvalid_0's rmse: 39.3584\n",
      "[16]\tvalid_0's rmse: 39.1686\n",
      "[18]\tvalid_0's rmse: 38.9946\n",
      "[20]\tvalid_0's rmse: 38.8149\n",
      "[22]\tvalid_0's rmse: 38.6731\n",
      "[24]\tvalid_0's rmse: 38.5071\n",
      "[26]\tvalid_0's rmse: 38.3539\n",
      "[28]\tvalid_0's rmse: 38.225\n",
      "[30]\tvalid_0's rmse: 38.0919\n",
      "[32]\tvalid_0's rmse: 37.9499\n",
      "[34]\tvalid_0's rmse: 37.7886\n",
      "[36]\tvalid_0's rmse: 37.6561\n",
      "[38]\tvalid_0's rmse: 37.5463\n",
      "[40]\tvalid_0's rmse: 37.4056\n",
      "[42]\tvalid_0's rmse: 37.2837\n",
      "[44]\tvalid_0's rmse: 37.1806\n",
      "[46]\tvalid_0's rmse: 37.0492\n",
      "[48]\tvalid_0's rmse: 36.9364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 36.810379: 100%|##########| 5/5 [21:20<00:00, 139.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's rmse: 36.8104\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 36.8104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 36.810379: 100%|##########| 5/5 [21:20<00:00, 256.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.142144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's rmse: 41.9394\n",
      "[4]\tvalid_0's rmse: 41.5181\n",
      "[6]\tvalid_0's rmse: 41.2301\n",
      "[8]\tvalid_0's rmse: 41.0279\n",
      "[10]\tvalid_0's rmse: 40.8769\n",
      "[12]\tvalid_0's rmse: 40.7673\n",
      "[14]\tvalid_0's rmse: 40.6816\n",
      "[16]\tvalid_0's rmse: 40.6145\n",
      "[18]\tvalid_0's rmse: 40.5402\n",
      "[20]\tvalid_0's rmse: 40.4926\n",
      "[22]\tvalid_0's rmse: 40.4441\n",
      "[24]\tvalid_0's rmse: 40.3994\n",
      "[26]\tvalid_0's rmse: 40.3546\n",
      "[28]\tvalid_0's rmse: 40.3168\n",
      "[30]\tvalid_0's rmse: 40.2738\n",
      "[32]\tvalid_0's rmse: 40.232\n",
      "[34]\tvalid_0's rmse: 40.1929\n",
      "[36]\tvalid_0's rmse: 40.1462\n",
      "[38]\tvalid_0's rmse: 40.115\n",
      "[40]\tvalid_0's rmse: 40.089\n",
      "[42]\tvalid_0's rmse: 40.0572\n",
      "[44]\tvalid_0's rmse: 40.0261\n",
      "[46]\tvalid_0's rmse: 39.9982\n",
      "[48]\tvalid_0's rmse: 39.9736\n",
      "[50]\tvalid_0's rmse: 39.9451\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's rmse: 39.9451\n",
      "Model RMSE is:  36.81037880022666\n",
      "Model R2 Score is:  0.25150748630315467\n",
      "Model RMSE is:  39.945097050218116\n",
      "Model R2 Score is:  0.1185983705868171\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna._imports import try_import\n",
    "from optuna.integration import _lightgbm_tuner as lightgbm_tuner\n",
    "\n",
    "\n",
    "# Convert dataset to type of LightGBM\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_valid = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# Basic parameters for learning\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "}\n",
    "\n",
    "# Make Hyperparameters be Stepwise Optimization with Optuna\n",
    "tuned_booster = lightgbm_tuner.train(lgb_params, lgb_train,\n",
    "                                     valid_sets=lgb_valid,\n",
    "                                     num_boost_round=50,\n",
    "                                     early_stopping_rounds=5,\n",
    "                                     verbose_eval=2,\n",
    "                                     )\n",
    "\n",
    "# Also prepare a model with default parameters for comparison\n",
    "default_booster = lgb.train(lgb_params, lgb_train,\n",
    "                            valid_sets=lgb_valid,\n",
    "                            num_boost_round=50,\n",
    "                            early_stopping_rounds=5,\n",
    "                            verbose_eval=2,\n",
    "                            )\n",
    "\n",
    "# Score for Optuna\n",
    "y_pred_tuned = tuned_booster.predict(X_test)\n",
    "tuned_metric = mean_squared_error(y_test, y_pred_tuned)\n",
    "print('Model RMSE is: ',np.sqrt(mean_squared_error(y_test, y_pred_tuned)))\n",
    "print('Model R2 Score is: ',r2_score(y_test,y_pred_tuned))\n",
    "\n",
    "# Score for default\n",
    "y_pred_default = default_booster.predict(X_test)\n",
    "default_metric = mean_squared_error(y_test, y_pred_default)\n",
    "print('Model RMSE is: ',np.sqrt(mean_squared_error(y_test, y_pred_default)))\n",
    "print('Model R2 Score is: ',r2_score(y_test,y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "086b9b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE is:  36.81037880022666\n",
      "Model R2 Score is:  0.25150748630315467\n"
     ]
    }
   ],
   "source": [
    "print('Optimized Model RMSE is: ',np.sqrt(mean_squared_error(y_test, y_pred_tuned)))\n",
    "print('Optimized Model R2 Score is: ',r2_score(y_test,y_pred_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3823be90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE is:  39.945097050218116\n",
      "Model R2 Score is:  0.1185983705868171\n"
     ]
    }
   ],
   "source": [
    "print('Model RMSE is: ',np.sqrt(mean_squared_error(y_test, y_pred_default)))\n",
    "print('Model R2 Score is: ',r2_score(y_test,y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3bfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b6ed3ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940266, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.277316\n",
      "Model RMSE is:  36.7489610220986\n",
      "Model R2 Score is:  0.2540031083396377\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "params = {}\n",
    "params['learning_rate'] = 0.8277896457253541\n",
    "params['boosting_type'] = 'gbdt'\n",
    "#params['boosting_type'] = 'dart'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'rmse'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 62\n",
    "params['min_data'] = 55\n",
    "params['max_depth'] = 27\n",
    "y_train=y_train.ravel()\n",
    "reg= lgb.train(params, d_train, 100)\n",
    "results=reg.predict(X_test)\n",
    "print('Model RMSE is: ',np.sqrt(mean_squared_error(y_test, results)))\n",
    "print('Model R2 Score is: ',r2_score(y_test,results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ae023548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 3293510, number of used features: 17\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 3293510, number of used features: 17\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2605\n",
      "[LightGBM] [Info] Number of data points in the train set: 3293510, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.265009\n",
      "[LightGBM] [Info] Start training from score 5.272756\n",
      "[LightGBM] [Info] Start training from score 5.294176\n",
      "Current parameters:\n",
      " {'learning_rate': 0.8277896457253541, 'boosting_type': 'gbdt', 'objective': 'regression', 'metric': 'rmse', 'sub_feature': 0.5, 'num_leaves': 62, 'min_data': 55, 'max_depth': 27}\n",
      "\n",
      "Best num_boost_round: 100\n",
      "LightGBM Model Cross-validation MAE is: 21.608509540616378\n"
     ]
    }
   ],
   "source": [
    "# Cross-validate\n",
    "cv_results = lgb.cv(\n",
    "        params,\n",
    "        d_train,\n",
    "        num_boost_round=100,\n",
    "        nfold=3,\n",
    "        metrics='mae',\n",
    "        early_stopping_rounds=10,\n",
    "\n",
    "        stratified=False\n",
    "        )\n",
    "# Display results\n",
    "print('Current parameters:\\n', params)\n",
    "print('\\nBest num_boost_round:', len(cv_results['l1-mean']))\n",
    "print('LightGBM Model Cross-validation MAE is:', cv_results['l1-mean'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5076967",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9d9c3944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-d15b5e47772a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m }\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \n\u001b[0m\u001b[1;32m     34\u001b[0m                                  param_grid, cv=5)\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-d15b5e47772a>\u001b[0m in \u001b[0;36malgorithm_pipeline\u001b[0;34m(X_train_data, X_test_data, y_train_data, y_test_data, model, param_grid, cv, scoring_fit, do_probabilities)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mfitted_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_probabilities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Paramter Optimization with Gridsearchcv\n",
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv=3, scoring_fit='neg_mean_squared_error',\n",
    "                       do_probabilities = False):\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid, \n",
    "        cv=cv, \n",
    "        n_jobs=-1, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=1\n",
    "    )\n",
    "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
    "    \n",
    "    if do_probabilities:\n",
    "        pred = fitted_model.predict_proba(X_test_data)\n",
    "    else:\n",
    "        pred = fitted_model.predict(X_test_data)\n",
    "    \n",
    "    return fitted_model, pred\n",
    "\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50],\n",
    "    'colsample_bytree': [0.3, 0.8],\n",
    "    'max_depth': [5,10,20],\n",
    "    'reg_alpha': [0.1, 1, 10],\n",
    "#    'reg_lambda': [1.1, 1.2, 1.3],\n",
    "    'learning_rate' : [0.1,0.3]\n",
    "}\n",
    "\n",
    "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \n",
    "                                 param_grid, cv=5)\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print(np.sqrt(-model.best_score_))\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6a180ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE is:  41.404632854318145\n",
      "Model R2 Score is:  0.05301137211503881\n"
     ]
    }
   ],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(X_test,y_test)\n",
    "\n",
    "y_pred_xgb = xg_reg.predict(X_test)\n",
    "\n",
    "print('Model RMSE is: ',np.sqrt(mean_squared_error(y_test, y_pred_xgb)))\n",
    "print('Model R2 Score is: ',r2_score(y_test,y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d3898edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3600x3600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Examine the importance of each feature column in the original data set with the model\n",
    "xgb.plot_importance(xg_reg)\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f374acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective':'reg:squarederror', 'colsample_bytree' : 0.3, 'learning_rate' : 0.1,\n",
    "                'max_depth' : 5, 'alpha' : 10}\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"mae\", as_pandas=True, seed=123)\n",
    "\n",
    "print('XGBoost Model Cross-validation MAE is: ',(cv_results[\"test-mae-mean\"]).tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa68963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# CV model\n",
    "model = xg_reg\n",
    "kfold = StratifiedKFold(n_splits=10)\n",
    "results = cross_val_score(model, X_test, y_test, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1930f2d",
   "metadata": {},
   "source": [
    "##### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0dad6a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE is:  41.04430751169987\n",
      "Model R2 Score is:  0.09010982648453558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "# creating linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_lr = lr.predict(X_test)\n",
    "\n",
    "print('Model RMSE is: ',np.sqrt(mean_squared_error(y_test, y_lr)))\n",
    "print('Model R2 Score is: ',r2_score(y_test,y_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c783a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model Cross-validation MAE is:  22.952193890281674\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "\n",
    "#define cross-validation method to use\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "#build multiple linear regression model\n",
    "model = lr\n",
    "\n",
    "#use k-fold CV to evaluate model\n",
    "scores = cross_val_score(model, X_test, y_test, scoring='neg_mean_absolute_error',\n",
    "                         cv=cv, n_jobs=-1)\n",
    "\n",
    "#view mean absolute error\n",
    "print('Linear Model Cross-validation MAE is: ',mean(absolute(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c6c43d",
   "metadata": {},
   "source": [
    "##### Ridge/Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a9b0e9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE is:  41.04431207827157\n",
      "Model R2 Score is:  0.0901096240165592\n",
      "Model RMSE is:  41.15480814567792\n",
      "Model R2 Score is:  0.08520396791066198\n"
     ]
    }
   ],
   "source": [
    "ridgereg = Ridge(alpha=0.001,normalize=True)\n",
    "ridge = ridgereg.fit(X_train,y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "print('Model RMSE is: ',np.sqrt(mean_squared_error(y_test, y_pred_ridge)))\n",
    "print('Model R2 Score is: ',r2_score(y_test,y_pred_ridge))\n",
    "\n",
    "lassoreg = Lasso(alpha=0.001,normalize=True)\n",
    "lasso = lassoreg.fit(X_train,y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "print('Model RMSE is: ',np.sqrt(mean_squared_error(y_test, y_pred_lasso)))\n",
    "print('Model R2 Score is: ',r2_score(y_test,y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bff70e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE is:  41.04431207827157\n",
      "Model R2 Score is:  0.0901096240165592\n",
      "Model RMSE is:  41.15480814567792\n",
      "Model R2 Score is:  0.08520396791066198\n"
     ]
    }
   ],
   "source": [
    "ridgereg = Ridge(alpha=0.001,normalize=True)\n",
    "ridge = ridgereg.fit(X_train,y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "print('Model RMSE is: ',np.sqrt(mean_squared_error(y_test, y_pred_ridge)))\n",
    "print('Model R2 Score is: ',r2_score(y_test,y_pred_ridge))\n",
    "\n",
    "lassoreg = Lasso(alpha=0.001,normalize=True)\n",
    "lasso = lassoreg.fit(X_train,y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "print('Model RMSE is: ',np.sqrt(mean_squared_error(y_test, y_pred_lasso)))\n",
    "print('Model R2 Score is: ',r2_score(y_test,y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce03f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LighthouseLabs",
   "language": "python",
   "name": "lighthouselabs"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
